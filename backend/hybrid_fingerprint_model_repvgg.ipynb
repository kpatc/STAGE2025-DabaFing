{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:40.083304Z",
          "iopub.status.busy": "2025-06-22T15:31:40.082482Z",
          "iopub.status.idle": "2025-06-22T15:31:40.094321Z",
          "shell.execute_reply": "2025-06-22T15:31:40.093444Z",
          "shell.execute_reply.started": "2025-06-22T15:31:40.083267Z"
        },
        "trusted": true,
        "id": "USqGRuAsfYBn",
        "outputId": "d735e4d7-2c06-4174-b9a1-f93f146633c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 42 for reproducibility.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "import torchmetrics\n",
        "from collections import defaultdict, OrderedDict\n",
        "import math\n",
        "import torchvision.models as models\n",
        "\n",
        "def set_seed(seed_value):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Random seed set to {seed_value} for reproducibility.\")\n",
        "\n",
        "MY_SEED = 42\n",
        "set_seed(MY_SEED)\n",
        "DEVICE      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "REG_IMPORTANCE=0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:40.096124Z",
          "iopub.status.busy": "2025-06-22T15:31:40.095787Z",
          "iopub.status.idle": "2025-06-22T15:31:40.117543Z",
          "shell.execute_reply": "2025-06-22T15:31:40.116773Z",
          "shell.execute_reply.started": "2025-06-22T15:31:40.096083Z"
        },
        "trusted": true,
        "id": "oXIE7AFGfYCD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class FingerprintDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Path to the dataset split (Train, Validation, or Test).\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.label_to_idx = {\n",
        "            'AC': 0, 'Ambiguous': 1, 'TA': 2, 'SA': 3, 'TAUL_TARL': 4, 'UL_RL': 5,\n",
        "            'SW': 6, 'TCW': 7, 'UPE_RPE': 8, 'DL': 9, 'ESW': 10, 'ECW': 11\n",
        "        }\n",
        "\n",
        "        self.idx_to_label = {v: k for k, v in self.label_to_idx.items()}\n",
        "        self.class_names = [self.idx_to_label[i] for i in sorted(self.idx_to_label.keys())]\n",
        "\n",
        "        self.zero_ridge_classes = {'AC', 'Ambiguous', 'TA', 'SA'}\n",
        "        self._prepare_dataset()\n",
        "\n",
        "    def _prepare_dataset(self):\n",
        "        for class_name in os.listdir(self.root_dir):\n",
        "            class_path = os.path.join(self.root_dir, class_name)\n",
        "            if not os.path.isdir(class_path):\n",
        "                continue\n",
        "            label = self.label_to_idx[class_name]\n",
        "            for fname in os.listdir(class_path):\n",
        "                if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
        "                    continue\n",
        "                img_path = os.path.join(class_path, fname)\n",
        "                ridge_count = self._get_ridge_count(fname, class_name)\n",
        "                self.data.append((img_path, label, ridge_count))\n",
        "\n",
        "    def _get_ridge_count(self, filename, class_name):\n",
        "        if class_name in self.zero_ridge_classes:\n",
        "            return 0\n",
        "        name_without_ext, _ = os.path.splitext(filename)\n",
        "        base = name_without_ext.split('_aug')[0] if '_aug' in name_without_ext else name_without_ext\n",
        "        parts = base.split('_')\n",
        "        try:\n",
        "\n",
        "            return int(parts[-1])\n",
        "        except ValueError:\n",
        "            return 0  # fallback if parsing fails\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label, ridge_count = self.data[idx]\n",
        "        image = Image.open(img_path).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image,(label,ridge_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:40.118664Z",
          "iopub.status.busy": "2025-06-22T15:31:40.118394Z",
          "iopub.status.idle": "2025-06-22T15:31:40.229904Z",
          "shell.execute_reply": "2025-06-22T15:31:40.229070Z",
          "shell.execute_reply.started": "2025-06-22T15:31:40.118641Z"
        },
        "trusted": true,
        "id": "lSrLRHGFfYCK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize grayscale (L mode)\n",
        "])\n",
        "\n",
        "train_dataset = FingerprintDataset('/kaggle/input/dataset-augmented/content/drive/MyDrive/Fingerprint wharehouse/Dataset-augmented/Train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "val_dataset = FingerprintDataset('/kaggle/input/dataset-augmented/content/drive/MyDrive/Fingerprint wharehouse/Dataset-augmented/Validation', transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = FingerprintDataset('/kaggle/input/dataset-augmented/content/drive/MyDrive/Fingerprint wharehouse/Dataset-augmented/Test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "CLASS_NAMES = train_dataset.class_names\n",
        "NUM_CLASSES = len(CLASS_NAMES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:40.231052Z",
          "iopub.status.busy": "2025-06-22T15:31:40.230771Z",
          "iopub.status.idle": "2025-06-22T15:31:40.235403Z",
          "shell.execute_reply": "2025-06-22T15:31:40.234607Z",
          "shell.execute_reply.started": "2025-06-22T15:31:40.231026Z"
        },
        "trusted": true,
        "id": "0BV6-MLpfYCO"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "from torch import nn\n",
        "\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "criterion_reg = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:40.237183Z",
          "iopub.status.busy": "2025-06-22T15:31:40.236865Z",
          "iopub.status.idle": "2025-06-22T15:31:40.258096Z",
          "shell.execute_reply": "2025-06-22T15:31:40.257266Z",
          "shell.execute_reply.started": "2025-06-22T15:31:40.237166Z"
        },
        "trusted": true,
        "id": "B1vLgsE1fYCQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchmetrics\n",
        "\n",
        "def run_epoch(model, loader, train=True, optimizer=None, criterion_cls=None, criterion_reg=None, DEVICE=None, NUM_CLASSES=None, REG_IMPORTANCE=None):\n",
        "    # Classification metrics (keeping only per-class and macro)\n",
        "    accuracy_per = torchmetrics.Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\").to(DEVICE)\n",
        "    accuracy_macro = torchmetrics.Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\").to(DEVICE)\n",
        "\n",
        "    accuracy_global = torchmetrics.Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"micro\").to(DEVICE)\n",
        "\n",
        "    precision_per = torchmetrics.Precision(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\", zero_division=0).to(DEVICE)\n",
        "    recall_per = torchmetrics.Recall(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\", zero_division=0).to(DEVICE)\n",
        "    f1_per = torchmetrics.F1Score(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\", zero_division=0).to(DEVICE)\n",
        "\n",
        "    precision_macro = torchmetrics.Precision(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\", zero_division=0).to(DEVICE)\n",
        "    recall_macro = torchmetrics.Recall(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\", zero_division=0).to(DEVICE)\n",
        "    f1_macro = torchmetrics.F1Score(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\", zero_division=0).to(DEVICE)\n",
        "\n",
        "    specificity_per = torchmetrics.Specificity(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\", zero_division=0).to(DEVICE)\n",
        "    specificity_macro = torchmetrics.Specificity(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\", zero_division=0).to(DEVICE)\n",
        "\n",
        "    conf_mat = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "    all_classification_preds = []\n",
        "    all_classification_targets = []\n",
        "\n",
        "    preds_per_class_reg = defaultdict(list)\n",
        "    targets_per_class_reg = defaultdict(list)\n",
        "\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    # Reset all classification metrics\n",
        "    accuracy_per.reset(); accuracy_macro.reset(); accuracy_global.reset()\n",
        "    precision_per.reset(); recall_per.reset(); f1_per.reset()\n",
        "    precision_macro.reset(); recall_macro.reset(); f1_macro.reset()\n",
        "    specificity_per.reset(); specificity_macro.reset()\n",
        "    conf_mat.reset()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.set_grad_enabled(train):\n",
        "        for imgs, (class_labels, ridge_counts) in loader:\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            class_labels = class_labels.to(DEVICE)\n",
        "            ridge_counts = ridge_counts.to(DEVICE).float()\n",
        "\n",
        "            class_logits, ridge_preds = model(imgs)\n",
        "\n",
        "            loss_cls = criterion_cls(class_logits, class_labels)\n",
        "            ridge_preds = ridge_preds.squeeze()\n",
        "            loss_reg = criterion_reg(ridge_preds, ridge_counts)\n",
        "            loss = (1 - REG_IMPORTANCE) * loss_cls + REG_IMPORTANCE * loss_reg\n",
        "\n",
        "            if train:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            batch_size = imgs.size(0)\n",
        "            total_loss += loss.item() * batch_size\n",
        "            total_samples += batch_size\n",
        "\n",
        "            preds_prob = class_logits.argmax(dim=1)\n",
        "\n",
        "            # Update classification metrics\n",
        "            accuracy_per.update(preds_prob, class_labels)\n",
        "            accuracy_macro.update(preds_prob, class_labels)\n",
        "            accuracy_global.update(preds_prob, class_labels)\n",
        "\n",
        "            precision_per.update(preds_prob, class_labels)\n",
        "            recall_per.update(preds_prob, class_labels)\n",
        "            f1_per.update(preds_prob, class_labels)\n",
        "\n",
        "            precision_macro.update(preds_prob, class_labels)\n",
        "            recall_macro.update(preds_prob, class_labels)\n",
        "            f1_macro.update(preds_prob, class_labels)\n",
        "\n",
        "            specificity_per.update(preds_prob, class_labels)\n",
        "            specificity_macro.update(preds_prob, class_labels)\n",
        "\n",
        "            conf_mat.update(preds_prob, class_labels)\n",
        "\n",
        "            all_classification_preds.extend(preds_prob.cpu().tolist())\n",
        "            all_classification_targets.extend(class_labels.cpu().tolist())\n",
        "\n",
        "            # Accumulate per-class regression preds and targets for macro calculation\n",
        "            class_labels_cpu = class_labels.cpu().numpy()\n",
        "            ridge_preds_cpu = ridge_preds.detach().cpu().numpy()\n",
        "            ridge_targets_cpu = ridge_counts.cpu().numpy()\n",
        "            for c, p, t in zip(class_labels_cpu, ridge_preds_cpu, ridge_targets_cpu):\n",
        "                preds_per_class_reg[c].append(p)\n",
        "                targets_per_class_reg[c].append(t)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Compute classification metrics\n",
        "    accuracy_per_val = accuracy_per.compute().cpu().numpy()\n",
        "    accuracy_macro_val = accuracy_macro.compute().item()\n",
        "    accuracy_global_val = accuracy_global.compute().item()\n",
        "\n",
        "    precision_per_val = precision_per.compute().cpu().numpy()\n",
        "    recall_per_val = recall_per.compute().cpu().numpy()\n",
        "    f1_per_val = f1_per.compute().cpu().numpy()\n",
        "\n",
        "    precision_macro_val = precision_macro.compute().item()\n",
        "    recall_macro_val = recall_macro.compute().item()\n",
        "    f1_macro_val = f1_macro.compute().item()\n",
        "\n",
        "    specificity_per_val = specificity_per.compute().cpu().numpy()\n",
        "    specificity_macro_val = specificity_macro.compute().item()\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    conf_mat_val = conf_mat.compute().cpu().numpy()\n",
        "\n",
        "    # Compute per-class regression metrics and then macro-average them\n",
        "    mse_per_class_reg = np.full(NUM_CLASSES, np.nan)\n",
        "    mae_per_class_reg = np.full(NUM_CLASSES, np.nan)\n",
        "    r2_per_class_reg = np.full(NUM_CLASSES, np.nan)\n",
        "\n",
        "    # Lists to hold per-class metric values for macro averaging\n",
        "    mse_values_for_macro = []\n",
        "    mae_values_for_macro = []\n",
        "    r2_values_for_macro = []\n",
        "\n",
        "    for c in range(NUM_CLASSES): # Iterate through all possible classes\n",
        "        preds_c = torch.tensor(preds_per_class_reg[c])\n",
        "        targets_c = torch.tensor(targets_per_class_reg[c])\n",
        "\n",
        "        if len(preds_c) > 0:\n",
        "            mse_val = torchmetrics.functional.mean_squared_error(preds_c, targets_c).item()\n",
        "            mae_val = torchmetrics.functional.mean_absolute_error(preds_c, targets_c).item()\n",
        "\n",
        "            mse_per_class_reg[c] = mse_val\n",
        "            mae_per_class_reg[c] = mae_val\n",
        "\n",
        "            # R2 needs variability in targets\n",
        "            if len(torch.unique(targets_c)) > 1:\n",
        "                r2_val = torchmetrics.functional.r2_score(preds_c, targets_c).item()\n",
        "                r2_per_class_reg[c] = r2_val\n",
        "            else:\n",
        "                r2_per_class_reg[c] = 0.0 # Assign 0 if no variability for R2 (perfect prediction of a constant)\n",
        "\n",
        "            # Add to lists for macro averaging if the class was present in the batch\n",
        "            mse_values_for_macro.append(mse_per_class_reg[c])\n",
        "            mae_values_for_macro.append(mae_per_class_reg[c])\n",
        "            r2_values_for_macro.append(r2_per_class_reg[c])\n",
        "\n",
        "    # Compute macro-averaged regression metrics\n",
        "    mse_macro_val = np.mean(mse_values_for_macro) if mse_values_for_macro else np.nan\n",
        "    mae_macro_val = np.mean(mae_values_for_macro) if mae_values_for_macro else np.nan\n",
        "    r2_macro_val = np.mean(r2_values_for_macro) if r2_values_for_macro else np.nan\n",
        "\n",
        "\n",
        "    metrics = {\n",
        "        \"loss\": avg_loss,\n",
        "        # Classification metrics\n",
        "        \"accuracy_per_class\": accuracy_per_val, # This is a NumPy array\n",
        "        \"accuracy_macro\": accuracy_macro_val,\n",
        "        \"accuracy_global\": accuracy_global_val,\n",
        "        \"precision_per_class\": precision_per_val, # This is a NumPy array\n",
        "        \"recall_per_class\": recall_per_val, # This is a NumPy array\n",
        "        \"f1_per_class\": f1_per_val, # This is a NumPy array\n",
        "        \"specificity_per_class\": specificity_per_val, # Specificity per class\n",
        "        \"precision_macro\": precision_macro_val,\n",
        "        \"recall_macro\": recall_macro_val,\n",
        "        \"f1_macro\": f1_macro_val,\n",
        "        \"specificity_macro\": specificity_macro_val, # Specificity macro\n",
        "        \"confusion_matrix\": conf_mat_val, # This is a NumPy array\n",
        "        \"raw_classification_preds\": all_classification_preds, # List of Python ints\n",
        "        \"raw_classification_targets\": all_classification_targets, # List of Python ints\n",
        "        # Regression metrics\n",
        "        \"mse_per_class\": mse_per_class_reg, # This is a NumPy array\n",
        "        \"mae_per_class\": mae_per_class_reg, # This is a NumPy array\n",
        "        \"r2_per_class\": r2_per_class_reg, # This is a NumPy array\n",
        "        \"mse_macro\": mse_macro_val,\n",
        "        \"mae_macro\": mae_macro_val,\n",
        "        \"r2_macro\": r2_macro_val,\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKwXYOSBfYCW"
      },
      "source": [
        "# Setup monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:40.368780Z",
          "iopub.status.busy": "2025-06-22T15:31:40.368076Z",
          "iopub.status.idle": "2025-06-22T15:31:43.441405Z",
          "shell.execute_reply": "2025-06-22T15:31:43.440346Z",
          "shell.execute_reply.started": "2025-06-22T15:31:40.368753Z"
        },
        "trusted": true,
        "id": "VTyJgbVufYCd"
      },
      "outputs": [],
      "source": [
        "! pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:43.443539Z",
          "iopub.status.busy": "2025-06-22T15:31:43.443226Z",
          "iopub.status.idle": "2025-06-22T15:31:49.348276Z",
          "shell.execute_reply": "2025-06-22T15:31:49.347693Z",
          "shell.execute_reply.started": "2025-06-22T15:31:43.443510Z"
        },
        "trusted": true,
        "id": "SQptBThAfYCg",
        "outputId": "a59bc310-6117-4b9b-957b-20b7e25a6d50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mossamaoutmani\u001b[0m (\u001b[33mossamaoutmani-nexos\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import wandb\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "user_secrets = UserSecretsClient()\n",
        "os.environ[\"WANDB_API_KEY\"] = user_secrets.get_secret(\"wandb_api\")\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:49.349434Z",
          "iopub.status.busy": "2025-06-22T15:31:49.349020Z",
          "iopub.status.idle": "2025-06-22T15:31:49.352849Z",
          "shell.execute_reply": "2025-06-22T15:31:49.352315Z",
          "shell.execute_reply.started": "2025-06-22T15:31:49.349415Z"
        },
        "trusted": true,
        "id": "0npu25XUfYCl"
      },
      "outputs": [],
      "source": [
        "if wandb.run is not None:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "VnI9-ntxfYCo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaoMvpkzfYCq"
      },
      "source": [
        "# ONNX Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:49.354506Z",
          "iopub.status.busy": "2025-06-22T15:31:49.354309Z",
          "iopub.status.idle": "2025-06-22T15:31:56.952706Z",
          "shell.execute_reply": "2025-06-22T15:31:56.951951Z",
          "shell.execute_reply.started": "2025-06-22T15:31:49.354491Z"
        },
        "trusted": true,
        "id": "uzVTEQi2fYCr",
        "outputId": "2f89f1f3-47fb-4a6f-d4f8-c9f3c0bfee6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q onnx\n",
        "!pip install -q onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:56.953823Z",
          "iopub.status.busy": "2025-06-22T15:31:56.953613Z",
          "iopub.status.idle": "2025-06-22T15:31:56.959691Z",
          "shell.execute_reply": "2025-06-22T15:31:56.958870Z",
          "shell.execute_reply.started": "2025-06-22T15:31:56.953803Z"
        },
        "trusted": true,
        "id": "W04pUxJNfYCu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def save_onnx(model,model_path):\n",
        "\n",
        "    # 1) Put model in eval mode\n",
        "    model = model.module if isinstance(model, torch.nn.DataParallel) else model\n",
        "    model.eval()\n",
        "\n",
        "    # 2) Create a dummy input matching your training dimensions\n",
        "    device = next(model.parameters()).device\n",
        "    dummy_input = torch.randn(1, 3, 224, 224, device=device)\n",
        "\n",
        "    # 3) Export to ONNX\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        model_path,\n",
        "        export_params=True,        # store weights\n",
        "        opset_version=17,          # use a recent ONNX opset\n",
        "        do_constant_folding=True,  # pre-fold constants for speed\n",
        "        input_names=[\"input\"],     # names for graph inputs\n",
        "        output_names=[\"output\"],   # names for graph outputs\n",
        "        dynamic_axes={             # allow variable batch size\n",
        "            \"input\": {0: \"batch\"},\n",
        "            \"output\": {0: \"batch\"}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(model_path ,\"saved successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffbtE09nfYCx"
      },
      "source": [
        "# Repvgg model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:56.960888Z",
          "iopub.status.busy": "2025-06-22T15:31:56.960622Z",
          "iopub.status.idle": "2025-06-22T15:31:56.979539Z",
          "shell.execute_reply": "2025-06-22T15:31:56.978898Z",
          "shell.execute_reply.started": "2025-06-22T15:31:56.960871Z"
        },
        "trusted": true,
        "id": "8CvFjoQgfYCz"
      },
      "outputs": [],
      "source": [
        "if wandb.run is not None:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:31:56.980477Z",
          "iopub.status.busy": "2025-06-22T15:31:56.980210Z",
          "iopub.status.idle": "2025-06-22T15:32:03.633773Z",
          "shell.execute_reply": "2025-06-22T15:32:03.633144Z",
          "shell.execute_reply.started": "2025-06-22T15:31:56.980440Z"
        },
        "trusted": true,
        "id": "udwnYUfWfYC1",
        "outputId": "f55ddc6a-5717-42a1-eba7-96ba78b56509"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20250622_153157-10d6g77d</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d' target=\"_blank\">repvgg_model-run</a></strong> to <a href='https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount' target=\"_blank\">https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d' target=\"_blank\">https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ad30df27c50>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project=\"Fingerprint-classification-ridgecount\",entity=\"elharkaouimeriem-ensa\",\n",
        "    reinit=False,\n",
        "    name=\"repvgg_model-run\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:32:03.634790Z",
          "iopub.status.busy": "2025-06-22T15:32:03.634528Z",
          "iopub.status.idle": "2025-06-22T15:32:04.393744Z",
          "shell.execute_reply": "2025-06-22T15:32:04.393020Z",
          "shell.execute_reply.started": "2025-06-22T15:32:03.634767Z"
        },
        "trusted": true,
        "id": "tXGo5HiMfYC2"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class RepVGGMultiTask(nn.Module):\n",
        "    def __init__(self, num_classes=12, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        # Load pre-trained RepVGG-A2 from timm\n",
        "        self.base_model = timm.create_model('repvgg_a2', pretrained=True)\n",
        "\n",
        "        in_features = self.base_model.num_features\n",
        "\n",
        "        # Replace the original classifier head with an Identity layer.\n",
        "        self.base_model.head = nn.Identity()\n",
        "\n",
        "        # Add a Dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        # Classification head\n",
        "        self.class_head = nn.Linear(in_features, num_classes)\n",
        "\n",
        "        # Ridge count regression head\n",
        "        self.ridge_head = nn.Linear(in_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.forward_features(x)\n",
        "\n",
        "        features = F.adaptive_avg_pool2d(features, (1, 1))\n",
        "        features = torch.flatten(features, 1)\n",
        "        features = self.dropout(features)\n",
        "\n",
        "        class_logits = self.class_head(features)\n",
        "        ridge_output = self.ridge_head(features)\n",
        "        return class_logits, ridge_output.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:32:04.394769Z",
          "iopub.status.busy": "2025-06-22T15:32:04.394589Z",
          "iopub.status.idle": "2025-06-22T15:32:05.995636Z",
          "shell.execute_reply": "2025-06-22T15:32:05.995015Z",
          "shell.execute_reply.started": "2025-06-22T15:32:04.394754Z"
        },
        "trusted": true,
        "id": "c-cPhfLtfYC5",
        "outputId": "bb836212-2985-44c9-a61b-7ad9287aa7e3",
        "colab": {
          "referenced_widgets": [
            "56257bbe8dad49afa3457b7d096de7eb"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56257bbe8dad49afa3457b7d096de7eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using single GPU.\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "repvgg_model = RepVGGMultiTask(num_classes=NUM_CLASSES, dropout_rate=0.5).to(DEVICE)\n",
        "\n",
        "# If using DataParallel, ensure the model variable name is updated\n",
        "# and device_ids are correct for your setup.\n",
        "if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
        "    print(f\"Using {torch.cuda.device_count()} GPUs for DataParallel.\")\n",
        "    repvgg_model = nn.DataParallel(repvgg_model).to(DEVICE) # .cuda() is redundant if .to(DEVICE) handles it\n",
        "elif torch.cuda.is_available():\n",
        "    print(\"Using single GPU.\")\n",
        "else:\n",
        "    print(\"Using CPU.\")\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(repvgg_model.parameters(), lr=1e-4)\n",
        "\n",
        "# Losses (remain the same as they are generic)\n",
        "classification_loss_fn = nn.CrossEntropyLoss()\n",
        "regression_loss_fn = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:32:05.997859Z",
          "iopub.status.busy": "2025-06-22T15:32:05.997650Z",
          "iopub.status.idle": "2025-06-22T15:42:45.159237Z",
          "shell.execute_reply": "2025-06-22T15:42:45.158392Z",
          "shell.execute_reply.started": "2025-06-22T15:32:05.997843Z"
        },
        "trusted": true,
        "id": "sepIRF1LfYC7",
        "outputId": "efffb1a8-b7cc-474d-ce0c-d915ada91096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01\n",
            "  Train | Loss 7.2342, Acc_macro 0.5060, Acc_global 0.5072, F1_macro 0.5090, Prec_macro 0.5183, Rec_macro 0.5060, Spec_macro 0.9552\n",
            "    Class AC          : Acc 0.6831, Prec 0.8428, Rec 0.6831, F1 0.7546, Spec 0.9881\n",
            "    Class Ambiguous   : Acc 0.5395, Prec 0.6208, Rec 0.5395, F1 0.5773, Spec 0.9699\n",
            "    Class TA          : Acc 0.5729, Prec 0.6463, Rec 0.5729, F1 0.6074, Spec 0.9726\n",
            "    Class SA          : Acc 0.5289, Prec 0.6359, Rec 0.5289, F1 0.5775, Spec 0.9769\n",
            "    Class TAUL_TARL   : Acc 0.6277, Prec 0.5296, Rec 0.6277, F1 0.5745, Spec 0.9524\n",
            "    Class UL_RL       : Acc 0.6791, Prec 0.5526, Rec 0.6791, F1 0.6094, Spec 0.9429\n",
            "    Class SW          : Acc 0.2748, Prec 0.2698, Rec 0.2748, F1 0.2723, Spec 0.9332\n",
            "    Class TCW         : Acc 0.4770, Prec 0.3925, Rec 0.4770, F1 0.4306, Spec 0.9318\n",
            "    Class UPE_RPE     : Acc 0.4643, Prec 0.4945, Rec 0.4643, F1 0.4789, Spec 0.9563\n",
            "    Class DL          : Acc 0.5095, Prec 0.4836, Rec 0.5095, F1 0.4962, Spec 0.9474\n",
            "    Class ESW         : Acc 0.3848, Prec 0.3549, Rec 0.3848, F1 0.3692, Spec 0.9372\n",
            "    Class ECW         : Acc 0.3300, Prec 0.3960, Rec 0.3300, F1 0.3600, Spec 0.9534\n",
            "  Train Regression | MSE_macro 12.7236, MAE_macro 2.3087, R2_macro -0.0068\n",
            "    Class AC           Regression: MSE 7.6212, MAE 1.3704, R2 0.0000\n",
            "    Class Ambiguous    Regression: MSE 26.9787, MAE 3.4431, R2 0.0000\n",
            "    Class TA           Regression: MSE 2.6770, MAE 0.9665, R2 0.0000\n",
            "    Class SA           Regression: MSE 1.2111, MAE 0.6219, R2 0.0000\n",
            "    Class TAUL_TARL    Regression: MSE 3.5935, MAE 1.4521, R2 -0.8767\n",
            "    Class UL_RL        Regression: MSE 18.3744, MAE 3.2143, R2 -0.4851\n",
            "    Class SW           Regression: MSE 13.6656, MAE 2.6171, R2 0.3925\n",
            "    Class TCW          Regression: MSE 9.7664, MAE 2.2288, R2 0.1806\n",
            "    Class UPE_RPE      Regression: MSE 17.0698, MAE 3.0000, R2 0.0945\n",
            "    Class DL           Regression: MSE 23.6486, MAE 3.4583, R2 0.5545\n",
            "    Class ESW          Regression: MSE 18.3060, MAE 3.0992, R2 -0.1566\n",
            "    Class ECW          Regression: MSE 9.7712, MAE 2.2333, R2 0.2142\n",
            "  Val  | Loss 5.8299, Acc_macro 0.6256, Acc_global 0.8024, F1_macro 0.6008, Prec_macro 0.5944, Rec_macro 0.6256, Spec_macro 0.9813\n",
            "    Class AC          : Acc 0.7143, Prec 0.7143, Rec 0.7143, F1 0.7143, Spec 0.9973\n",
            "    Class Ambiguous   : Acc 0.8609, Prec 0.9704, Rec 0.8609, F1 0.9124, Spec 0.9725\n",
            "    Class TA          : Acc 0.6562, Prec 0.7778, Rec 0.6562, F1 0.7119, Spec 0.9824\n",
            "    Class SA          : Acc 0.9059, Prec 0.7333, Rec 0.9059, F1 0.8105, Spec 0.9575\n",
            "    Class TAUL_TARL   : Acc 0.8421, Prec 0.6667, Rec 0.8421, F1 0.7442, Spec 0.9773\n",
            "    Class UL_RL       : Acc 0.8533, Prec 0.7033, Rec 0.8533, F1 0.7711, Spec 0.9596\n",
            "    Class SW          : Acc 0.6667, Prec 0.3871, Rec 0.6667, F1 0.4898, Spec 0.9738\n",
            "    Class TCW         : Acc 0.0000, Prec 0.0000, Rec 0.0000, F1 0.0000, Spec 0.9905\n",
            "    Class UPE_RPE     : Acc 0.5517, Prec 0.6957, Rec 0.5517, F1 0.6154, Spec 0.9902\n",
            "    Class DL          : Acc 0.7059, Prec 0.5455, Rec 0.7059, F1 0.6154, Spec 0.9862\n",
            "    Class ESW         : Acc 0.3500, Prec 0.5385, Rec 0.3500, F1 0.4242, Spec 0.9917\n",
            "    Class ECW         : Acc 0.4000, Prec 0.4000, Rec 0.4000, F1 0.4000, Spec 0.9959\n",
            "  Val  Regression | MSE_macro 7.5487, MAE_macro 1.5840, R2_macro 0.1643\n",
            "    Class AC           Regression: MSE 11.7443, MAE 1.6966, R2 0.0000\n",
            "    Class Ambiguous    Regression: MSE 15.7381, MAE 2.2248, R2 0.0000\n",
            "    Class TA           Regression: MSE 0.4169, MAE 0.4825, R2 0.0000\n",
            "    Class SA           Regression: MSE 0.4144, MAE 0.5024, R2 0.0000\n",
            "    Class TAUL_TARL    Regression: MSE 1.8402, MAE 1.1266, R2 -0.2411\n",
            "    Class UL_RL        Regression: MSE 16.9526, MAE 2.6265, R2 -0.0707\n",
            "    Class SW           Regression: MSE 3.2947, MAE 1.5441, R2 0.8170\n",
            "    Class TCW          Regression: MSE 10.1665, MAE 2.3145, R2 -0.8967\n",
            "    Class UPE_RPE      Regression: MSE 7.6017, MAE 1.7487, R2 0.5174\n",
            "    Class DL           Regression: MSE 11.3944, MAE 1.7348, R2 0.7963\n",
            "    Class ESW          Regression: MSE 8.7662, MAE 1.9266, R2 0.4012\n",
            "    Class ECW          Regression: MSE 2.2538, MAE 1.0805, R2 0.6478\n",
            "/kaggle/working/repvgg_best.onnx saved successfully\n",
            "*** New best model saved at epoch 1 with Val Macro F1: 0.6008 ***\n",
            "Epoch 02\n",
            "  Train | Loss 2.8070, Acc_macro 0.7230, Acc_global 0.7237, F1_macro 0.7214, Prec_macro 0.7215, Rec_macro 0.7230, Spec_macro 0.9749\n",
            "    Class AC          : Acc 0.9692, Prec 0.9341, Rec 0.9692, F1 0.9514, Spec 0.9936\n",
            "    Class Ambiguous   : Acc 0.8305, Prec 0.8276, Rec 0.8305, F1 0.8290, Spec 0.9842\n",
            "    Class TA          : Acc 0.7432, Prec 0.8090, Rec 0.7432, F1 0.7747, Spec 0.9847\n",
            "    Class SA          : Acc 0.7969, Prec 0.7741, Rec 0.7969, F1 0.7853, Spec 0.9823\n",
            "    Class TAUL_TARL   : Acc 0.8282, Prec 0.7864, Rec 0.8282, F1 0.8067, Spec 0.9808\n",
            "    Class UL_RL       : Acc 0.8511, Prec 0.7999, Rec 0.8511, F1 0.8247, Spec 0.9779\n",
            "    Class SW          : Acc 0.4444, Prec 0.4824, Rec 0.4444, F1 0.4626, Spec 0.9572\n",
            "    Class TCW         : Acc 0.7229, Prec 0.6292, Rec 0.7229, F1 0.6728, Spec 0.9606\n",
            "    Class UPE_RPE     : Acc 0.7063, Prec 0.7310, Rec 0.7063, F1 0.7185, Spec 0.9761\n",
            "    Class DL          : Acc 0.7061, Prec 0.7215, Rec 0.7061, F1 0.7137, Spec 0.9737\n",
            "    Class ESW         : Acc 0.5005, Prec 0.4942, Rec 0.5005, F1 0.4974, Spec 0.9540\n",
            "    Class ECW         : Acc 0.5766, Prec 0.6692, Rec 0.5766, F1 0.6194, Spec 0.9736\n",
            "  Train Regression | MSE_macro 4.7070, MAE_macro 1.4087, R2_macro 0.3998\n",
            "    Class AC           Regression: MSE 1.1061, MAE 0.5085, R2 0.0000\n",
            "    Class Ambiguous    Regression: MSE 12.8190, MAE 1.8727, R2 0.0000\n",
            "    Class TA           Regression: MSE 0.8042, MAE 0.5684, R2 0.0000\n",
            "    Class SA           Regression: MSE 0.4044, MAE 0.4567, R2 0.0000\n",
            "    Class TAUL_TARL    Regression: MSE 1.7807, MAE 1.0197, R2 0.0700\n",
            "    Class UL_RL        Regression: MSE 8.4397, MAE 2.1403, R2 0.3179\n",
            "    Class SW           Regression: MSE 5.3440, MAE 1.7383, R2 0.7624\n",
            "    Class TCW          Regression: MSE 3.2789, MAE 1.4263, R2 0.7249\n",
            "    Class UPE_RPE      Regression: MSE 5.8497, MAE 1.8158, R2 0.6897\n",
            "    Class DL           Regression: MSE 7.5632, MAE 2.0909, R2 0.8575\n",
            "    Class ESW          Regression: MSE 6.1659, MAE 1.9365, R2 0.6104\n",
            "    Class ECW          Regression: MSE 2.9275, MAE 1.3301, R2 0.7646\n",
            "  Val  | Loss 4.8629, Acc_macro 0.7360, Acc_global 0.8199, F1_macro 0.6799, Prec_macro 0.6489, Rec_macro 0.7360, Spec_macro 0.9829\n",
            "    Class AC          : Acc 0.8571, Prec 0.3750, Rec 0.8571, F1 0.5217, Spec 0.9864\n",
            "    Class Ambiguous   : Acc 0.8504, Prec 0.9701, Rec 0.8504, F1 0.9063, Spec 0.9725\n",
            "    Class TA          : Acc 0.7656, Prec 0.7656, Rec 0.7656, F1 0.7656, Spec 0.9779\n",
            "    Class SA          : Acc 0.9529, Prec 0.7642, Rec 0.9529, F1 0.8482, Spec 0.9621\n",
            "    Class TAUL_TARL   : Acc 0.7895, Prec 0.5769, Rec 0.7895, F1 0.6667, Spec 0.9688\n",
            "    Class UL_RL       : Acc 0.7067, Prec 0.8030, Rec 0.7067, F1 0.7518, Spec 0.9806\n",
            "    Class SW          : Acc 0.6111, Prec 0.5238, Rec 0.6111, F1 0.5641, Spec 0.9862\n",
            "    Class TCW         : Acc 0.4000, Prec 0.2857, Rec 0.4000, F1 0.3333, Spec 0.9932\n",
            "    Class UPE_RPE     : Acc 0.7931, Prec 0.6765, Rec 0.7931, F1 0.7302, Spec 0.9846\n",
            "    Class DL          : Acc 0.7059, Prec 0.7500, Rec 0.7059, F1 0.7273, Spec 0.9945\n",
            "    Class ESW         : Acc 0.8000, Prec 0.6957, Rec 0.8000, F1 0.7442, Spec 0.9903\n",
            "    Class ECW         : Acc 0.6000, Prec 0.6000, Rec 0.6000, F1 0.6000, Spec 0.9973\n",
            "  Val  Regression | MSE_macro 9.2216, MAE_macro 1.8458, R2_macro -0.2950\n",
            "    Class AC           Regression: MSE 5.0062, MAE 0.9524, R2 0.0000\n",
            "    Class Ambiguous    Regression: MSE 10.5044, MAE 1.4471, R2 0.0000\n",
            "    Class TA           Regression: MSE 0.1637, MAE 0.3514, R2 0.0000\n",
            "    Class SA           Regression: MSE 0.1762, MAE 0.3465, R2 0.0000\n",
            "    Class TAUL_TARL    Regression: MSE 2.4867, MAE 1.1335, R2 -0.6772\n",
            "    Class UL_RL        Regression: MSE 23.2711, MAE 3.4449, R2 -0.4697\n",
            "    Class SW           Regression: MSE 4.0467, MAE 1.6357, R2 0.7752\n",
            "    Class TCW          Regression: MSE 34.6928, MAE 4.4779, R2 -5.4726\n",
            "    Class UPE_RPE      Regression: MSE 7.8482, MAE 2.1991, R2 0.5017\n",
            "    Class DL           Regression: MSE 9.5170, MAE 2.3729, R2 0.8299\n",
            "    Class ESW          Regression: MSE 11.3160, MAE 2.7617, R2 0.2271\n",
            "    Class ECW          Regression: MSE 1.6299, MAE 1.0261, R2 0.7453\n",
            "/kaggle/working/repvgg_best.onnx saved successfully\n",
            "*** New best model saved at epoch 2 with Val Macro F1: 0.6799 ***\n",
            "/kaggle/working/repvgg_last.onnx saved successfully\n",
            "Last model saved. Val Macro F1: 0.6799\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "EPOCHS = 2 # Max number of epochs\n",
        "EARLY_STOPPING_PATIENCE = 25 # Number of epochs to wait for improvement before stopping\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_val_f1_macro = 0.0 # Use F1 Macro for early stopping as it balances precision and recall\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "best_metrics = {}\n",
        "best_train_metrics = {}\n",
        "last_metrics = {}\n",
        "last_train_metrics = {}\n",
        "\n",
        "# --- Track epoch numbers for best and last models ---\n",
        "best_epoch_num = 0\n",
        "last_epoch_num = 0 # Will be updated at the end of the loop\n",
        "\n",
        "BEST_PATH = \"/kaggle/working/repvgg_best.onnx\"\n",
        "LAST_PATH = \"/kaggle/working/repvgg_last.onnx\"\n",
        "BEST_PTH = \"/kaggle/working/repvgg_best.pth\"\n",
        "LAST_PTH = \"/kaggle/working/repvgg_last.pth\"\n",
        "\n",
        "\n",
        "current_model = repvgg_model\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_stats = run_epoch(current_model, train_loader, train=True, optimizer=optimizer, criterion_cls=classification_loss_fn, criterion_reg=regression_loss_fn, DEVICE=DEVICE, NUM_CLASSES=NUM_CLASSES, REG_IMPORTANCE=REG_IMPORTANCE)\n",
        "    val_stats = run_epoch(current_model, val_loader, train=False, optimizer=optimizer, criterion_cls=classification_loss_fn, criterion_reg=regression_loss_fn, DEVICE=DEVICE, NUM_CLASSES=NUM_CLASSES, REG_IMPORTANCE=REG_IMPORTANCE)\n",
        "\n",
        "    log_dict = {\"epoch\": epoch}\n",
        "\n",
        "    # 1. Track all training/validation metrics epoch-by-epoch\n",
        "    for phase in (\"train\", \"val\"):\n",
        "        stats = train_stats if phase == \"train\" else val_stats\n",
        "\n",
        "        # Log GLOBAL (Macro) Metrics directly to W&B run (per epoch)\n",
        "        log_dict[f\"{phase}/loss\"] = stats[\"loss\"]\n",
        "        log_dict[f\"{phase}/accuracy_macro\"] = stats[\"accuracy_macro\"]\n",
        "        log_dict[f\"{phase}/accuracy_global\"] = stats[\"accuracy_global\"]\n",
        "        log_dict[f\"{phase}/precision_macro\"] = stats[\"precision_macro\"]\n",
        "        log_dict[f\"{phase}/recall_macro\"] = stats[\"recall_macro\"]\n",
        "        log_dict[f\"{phase}/f1_macro\"] = stats[\"f1_macro\"]\n",
        "        log_dict[f\"{phase}/specificity_macro\"] = stats[\"specificity_macro\"]\n",
        "        log_dict[f\"{phase}/mse_macro\"] = stats[\"mse_macro\"]\n",
        "        log_dict[f\"{phase}/mae_macro\"] = stats[\"mae_macro\"]\n",
        "        log_dict[f\"{phase}/r2_macro\"] = stats[\"r2_macro\"]\n",
        "\n",
        "        # Log PER-CLASS Metrics individually for epoch-wise logging\n",
        "        for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "            # Use .item() to convert NumPy scalar to Python float for W&B logging\n",
        "            log_dict[f\"{phase}/accuracy_{class_name}\"] = stats[\"accuracy_per_class\"][cls_idx].item()\n",
        "            log_dict[f\"{phase}/precision_{class_name}\"] = stats[\"precision_per_class\"][cls_idx].item()\n",
        "            log_dict[f\"{phase}/recall_{class_name}\"] = stats[\"recall_per_class\"][cls_idx].item()\n",
        "            log_dict[f\"{phase}/f1_{class_name}\"] = stats[\"f1_per_class\"][cls_idx].item()\n",
        "            log_dict[f\"{phase}/specificity_{class_name}\"] = stats[\"specificity_per_class\"][cls_idx].item()\n",
        "            log_dict[f\"{phase}/mse_{class_name}\"] = stats[\"mse_per_class\"][cls_idx].item()\n",
        "            log_dict[f\"{phase}/mae_{class_name}\"] = stats[\"mae_per_class\"][cls_idx].item()\n",
        "            log_dict[f\"{phase}/r2_{class_name}\"] = stats[\"r2_per_class\"][cls_idx].item()\n",
        "\n",
        "        # Log confusion matrix to W&B\n",
        "        log_dict[f\"{phase}/confusion_matrix\"] = wandb.plot.confusion_matrix(\n",
        "                     preds=stats[\"raw_classification_preds\"],\n",
        "                     y_true=stats[\"raw_classification_targets\"],\n",
        "                     class_names=CLASS_NAMES\n",
        "                   )\n",
        "\n",
        "    wandb.log(log_dict)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}\")\n",
        "    for phase_name, stats in ((\"Train\", train_stats), (\"Val \", val_stats)):\n",
        "        print(\n",
        "            f\"  {phase_name} | \"\n",
        "            f\"Loss {stats['loss']:.4f}, Acc_macro {stats['accuracy_macro']:.4f}, \"\n",
        "            f\"Acc_global {stats['accuracy_global']:.4f}, \"\n",
        "            f\"F1_macro {stats['f1_macro']:.4f}, \"\n",
        "            f\"Prec_macro {stats['precision_macro']:.4f}, \"\n",
        "            f\"Rec_macro {stats['recall_macro']:.4f}, \"\n",
        "            f\"Spec_macro {stats['specificity_macro']:.4f}\"\n",
        "        )\n",
        "        for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "            a = stats['accuracy_per_class'][cls_idx]\n",
        "            p = stats['precision_per_class'][cls_idx]\n",
        "            r = stats['recall_per_class'][cls_idx]\n",
        "            f = stats['f1_per_class'][cls_idx]\n",
        "            s = stats['specificity_per_class'][cls_idx]\n",
        "            print(f\"    Class {class_name:<12}: Acc {a:.4f}, Prec {p:.4f}, Rec {r:.4f}, F1 {f:.4f}, Spec {s:.4f}\")\n",
        "\n",
        "        print(\n",
        "            f\"  {phase_name} Regression | MSE_macro {stats['mse_macro']:.4f}, \"\n",
        "            f\"MAE_macro {stats['mae_macro']:.4f}, R2_macro {stats['r2_macro']:.4f}\"\n",
        "        )\n",
        "        for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "            mse = stats['mse_per_class'][cls_idx]\n",
        "            mae = stats['mae_per_class'][cls_idx]\n",
        "            r2 = stats['r2_per_class'][cls_idx]\n",
        "            print(f\"    Class {class_name:<12} Regression: MSE {mse:.4f}, MAE {mae:.4f}, R2 {r2:.4f}\")\n",
        "\n",
        "    current_val_f1_macro = val_stats[\"f1_macro\"]\n",
        "    current_val_loss = val_stats[\"loss\"]\n",
        "\n",
        "    # --- Early Stopping Logic ---\n",
        "    # We prioritize F1_macro for best model, then loss if F1_macro is tied\n",
        "    if (current_val_f1_macro > best_val_f1_macro) or \\\n",
        "       (current_val_f1_macro == best_val_f1_macro and current_val_loss < best_val_loss):\n",
        "        best_val_f1_macro = current_val_f1_macro\n",
        "        best_val_loss = current_val_loss\n",
        "        epochs_without_improvement = 0 # Reset counter\n",
        "        best_metrics = val_stats.copy()\n",
        "        best_train_metrics = train_stats.copy()\n",
        "        best_epoch_num = epoch # Store the epoch number for the best model\n",
        "\n",
        "        save_onnx(current_model, BEST_PATH)\n",
        "        torch.save(current_model.state_dict(), BEST_PTH)\n",
        "        print(f\"*** New best model saved at epoch {epoch} with Val Macro F1: {best_val_f1_macro:.4f} ***\")\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        print(f\"No improvement for {epochs_without_improvement} epochs.\")\n",
        "        if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
        "            print(f\"Early stopping triggered after {EARLY_STOPPING_PATIENCE} epochs without improvement.\")\n",
        "            last_epoch_num = epoch # The last epoch before stopping\n",
        "            break # Exit training loop\n",
        "\n",
        "# --- Set last_epoch_num if loop completes naturally ---\n",
        "if epoch == EPOCHS: # If the loop ran for all epochs without early stopping\n",
        "    last_epoch_num = EPOCHS\n",
        "# If early stopping occurred, last_epoch_num was already set in the break condition\n",
        "\n",
        "# Save last epoch metrics (for the last model artifact)\n",
        "last_metrics = val_stats.copy()\n",
        "last_train_metrics = train_stats.copy()\n",
        "\n",
        "save_onnx(current_model, LAST_PATH)\n",
        "torch.save(current_model.state_dict(), LAST_PTH)\n",
        "print(f\"Last model saved. Val Macro F1: {last_metrics['f1_macro']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:42:45.160522Z",
          "iopub.status.busy": "2025-06-22T15:42:45.160101Z",
          "iopub.status.idle": "2025-06-22T15:43:06.094067Z",
          "shell.execute_reply": "2025-06-22T15:43:06.093296Z",
          "shell.execute_reply.started": "2025-06-22T15:42:45.160504Z"
        },
        "trusted": true,
        "id": "A8IPeCeBfYDA",
        "outputId": "3bf5ae12-7a55-43d9-cfb7-bea34777bd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "=== TEST RESULTS LAST MODEL ===\n",
            "Test | Loss 3.6584, Acc_macro 0.7306, Acc_global 0.8427, Prec_macro 0.6698, Rec_macro 0.7306, F1_macro 0.6851, Spec_macro 0.9844\n",
            "\n",
            "Per-Class Classification Metrics:\n",
            "  Class AC          : Acc 0.7500, Prec 0.5455, Rec 0.7500, F1 0.6316, Spec 0.9954\n",
            "  Class Ambiguous   : Acc 0.8969, Prec 0.9607, Rec 0.8969, F1 0.9277, Spec 0.9602\n",
            "  Class TA          : Acc 0.7292, Prec 0.8333, Rec 0.7292, F1 0.7778, Spec 0.9861\n",
            "  Class SA          : Acc 0.9524, Prec 0.8000, Rec 0.9524, F1 0.8696, Spec 0.9692\n",
            "  Class TAUL_TARL   : Acc 0.9091, Prec 0.6579, Rec 0.9091, F1 0.7634, Spec 0.9751\n",
            "  Class UL_RL       : Acc 0.7232, Prec 0.7570, Rec 0.7232, F1 0.7397, Spec 0.9737\n",
            "  Class SW          : Acc 0.6538, Prec 0.5312, Rec 0.6538, F1 0.5862, Spec 0.9860\n",
            "  Class TCW         : Acc 0.8333, Prec 0.3333, Rec 0.8333, F1 0.4762, Spec 0.9909\n",
            "  Class UPE_RPE     : Acc 0.7857, Prec 0.7674, Rec 0.7857, F1 0.7765, Spec 0.9905\n",
            "  Class DL          : Acc 0.4783, Prec 0.6471, Rec 0.4783, F1 0.5500, Spec 0.9944\n",
            "  Class ESW         : Acc 0.6552, Prec 0.7037, Rec 0.6552, F1 0.6786, Spec 0.9925\n",
            "  Class ECW         : Acc 0.4000, Prec 0.5000, Rec 0.4000, F1 0.4444, Spec 0.9982\n",
            "\n",
            "Macro Regression Metrics:\n",
            "  MSE_macro 6.8478, MAE_macro 1.6554, R2_macro 0.0436\n",
            "\n",
            "Per-Class Regression Metrics (MSE, MAE, R2):\n",
            "  Class AC          : MSE 1.1111, MAE 0.6874, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class Ambiguous   : MSE 6.8766, MAE 1.2698, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class TA          : MSE 0.4298, MAE 0.4434, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class SA          : MSE 0.2259, MAE 0.3429, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class TAUL_TARL   : MSE 2.3788, MAE 1.2094, R2 -0.1595\n",
            "  Class UL_RL       : MSE 17.4940, MAE 3.3150, R2 -0.7100\n",
            "  Class SW          : MSE 6.5448, MAE 1.8949, R2 0.6852\n",
            "  Class TCW         : MSE 9.0876, MAE 2.2936, R2 -1.1957\n",
            "  Class UPE_RPE     : MSE 11.1449, MAE 2.2254, R2 0.3775\n",
            "  Class DL          : MSE 15.5257, MAE 2.7539, R2 0.7265\n",
            "  Class ESW         : MSE 9.7990, MAE 2.3525, R2 0.4937\n",
            "  Class ECW         : MSE 1.5550, MAE 1.0767, R2 0.3058\n",
            "Model saved and pushed to W&B : https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "current_model.eval()\n",
        "test_last_stats = run_epoch(current_model, test_loader, train=False, optimizer=None, criterion_cls=classification_loss_fn, criterion_reg=regression_loss_fn, DEVICE=DEVICE, NUM_CLASSES=NUM_CLASSES, REG_IMPORTANCE=REG_IMPORTANCE)\n",
        "test_last_log = {\n",
        "    \"test/loss\": test_last_stats[\"loss\"],\n",
        "    \"test/accuracy_macro\": test_last_stats[\"accuracy_macro\"],\n",
        "    \"test/accuracy_global\": test_last_stats[\"accuracy_global\"],\n",
        "    \"test/precision_macro\": test_last_stats[\"precision_macro\"],\n",
        "    \"test/recall_macro\": test_last_stats[\"recall_macro\"],\n",
        "    \"test/f1_macro\": test_last_stats[\"f1_macro\"],\n",
        "    \"test/specificity_macro\": test_last_stats[\"specificity_macro\"],\n",
        "    \"test/mse_macro\": test_last_stats[\"mse_macro\"],\n",
        "    \"test/mae_macro\": test_last_stats[\"mae_macro\"],\n",
        "    \"test/r2_macro\": test_last_stats[\"r2_macro\"],\n",
        "    \"epochs_trained\": last_epoch_num # Log epoch number for last model\n",
        "}\n",
        "\n",
        "# Add per-class metrics as a nested dictionary to the artifact metadata for the last model (TEST)\n",
        "test_last_per_class_metrics = {}\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = test_last_stats[\"accuracy_per_class\"][cls_idx].item()\n",
        "    prec = test_last_stats[\"precision_per_class\"][cls_idx].item()\n",
        "    rec = test_last_stats[\"recall_per_class\"][cls_idx].item()\n",
        "    f1 = test_last_stats[\"f1_per_class\"][cls_idx].item()\n",
        "    spec = test_last_stats[\"specificity_per_class\"][cls_idx].item()\n",
        "    mse = test_last_stats[\"mse_per_class\"][cls_idx].item()\n",
        "    mae = test_last_stats[\"mae_per_class\"][cls_idx].item()\n",
        "    r2 = test_last_stats[\"r2_per_class\"][cls_idx].item()\n",
        "\n",
        "    test_last_per_class_metrics[class_name] = {\n",
        "        \"accuracy\": acc if not math.isnan(acc) else 0.0,\n",
        "        \"precision\": prec if not math.isnan(prec) else 0.0,\n",
        "        \"recall\": rec if not math.isnan(rec) else 0.0,\n",
        "        \"f1_score\": f1 if not math.isnan(f1) else 0.0,\n",
        "        \"specificity\": spec if not math.isnan(spec) else 0.0,\n",
        "        \"mse\": mse if not math.isnan(mse) else 0.0,\n",
        "        \"mae\": mae if not math.isnan(mae) else 0.0,\n",
        "        \"r2\": r2 if not math.isnan(r2) else 0.0,\n",
        "    }\n",
        "test_last_log[\"test/per_class_metrics\"] = test_last_per_class_metrics\n",
        "\n",
        "# Include LAST validation macro metrics in the artifact metadata\n",
        "test_last_log.update({\n",
        "    \"val_last/loss\": last_metrics[\"loss\"],\n",
        "    \"val_last/accuracy_macro\": last_metrics[\"accuracy_macro\"],\n",
        "    \"val_last/accuracy_global\": last_metrics[\"accuracy_global\"],\n",
        "    \"val_last/precision_macro\": last_metrics[\"precision_macro\"],\n",
        "    \"val_last/recall_macro\": last_metrics[\"recall_macro\"],\n",
        "    \"val_last/f1_macro\": last_metrics[\"f1_macro\"],\n",
        "    \"val_last/specificity_macro\": last_metrics[\"specificity_macro\"],\n",
        "    \"val_last/mse_macro\": last_metrics[\"mse_macro\"],\n",
        "    \"val_last/mae_macro\": last_metrics[\"mae_macro\"],\n",
        "    \"val_last/r2_macro\": last_metrics[\"r2_macro\"],\n",
        "})\n",
        "\n",
        "# Add per-class metrics as a nested dictionary to the artifact metadata for the last model (VAL)\n",
        "val_last_per_class_metrics = {}\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = last_metrics[\"accuracy_per_class\"][cls_idx].item()\n",
        "    prec = last_metrics[\"precision_per_class\"][cls_idx].item()\n",
        "    rec = last_metrics[\"recall_per_class\"][cls_idx].item()\n",
        "    f1 = last_metrics[\"f1_per_class\"][cls_idx].item()\n",
        "    spec = last_metrics[\"specificity_per_class\"][cls_idx].item()\n",
        "    mse = last_metrics[\"mse_per_class\"][cls_idx].item()\n",
        "    mae = last_metrics[\"mae_per_class\"][cls_idx].item()\n",
        "    r2 = last_metrics[\"r2_per_class\"][cls_idx].item()\n",
        "\n",
        "    val_last_per_class_metrics[class_name] = {\n",
        "        \"accuracy\": acc if not math.isnan(acc) else 0.0,\n",
        "        \"precision\": prec if not math.isnan(prec) else 0.0,\n",
        "        \"recall\": rec if not math.isnan(rec) else 0.0,\n",
        "        \"f1_score\": f1 if not math.isnan(f1) else 0.0,\n",
        "        \"specificity\": spec if not math.isnan(spec) else 0.0,\n",
        "        \"mse\": mse if not math.isnan(mse) else 0.0,\n",
        "        \"mae\": mae if not math.isnan(mae) else 0.0,\n",
        "        \"r2\": r2 if not math.isnan(r2) else 0.0,\n",
        "    }\n",
        "test_last_log[\"val_last/per_class_metrics\"] = val_last_per_class_metrics\n",
        "\n",
        "# Include LAST training macro metrics in the artifact metadata\n",
        "test_last_log.update({\n",
        "    \"train_last/loss\": last_train_metrics[\"loss\"],\n",
        "    \"train_last/accuracy_macro\": last_train_metrics[\"accuracy_macro\"],\n",
        "    \"train_last/accuracy_global\": last_train_metrics[\"accuracy_global\"],\n",
        "    \"train_last/precision_macro\": last_train_metrics[\"precision_macro\"],\n",
        "    \"train_last/recall_macro\": last_train_metrics[\"recall_macro\"],\n",
        "    \"train_last/f1_macro\": last_train_metrics[\"f1_macro\"],\n",
        "    \"train_last/specificity_macro\": last_train_metrics[\"specificity_macro\"],\n",
        "    \"train_last/mse_macro\": last_train_metrics[\"mse_macro\"],\n",
        "    \"train_last/mae_macro\": last_train_metrics[\"mae_macro\"],\n",
        "    \"train_last/r2_macro\": last_train_metrics[\"r2_macro\"],\n",
        "})\n",
        "\n",
        "# Add per-class metrics as a nested dictionary to the artifact metadata for the last model (TRAIN)\n",
        "train_last_per_class_metrics = {}\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = last_train_metrics[\"accuracy_per_class\"][cls_idx].item()\n",
        "    prec = last_train_metrics[\"precision_per_class\"][cls_idx].item()\n",
        "    rec = last_train_metrics[\"recall_per_class\"][cls_idx].item()\n",
        "    f1 = last_train_metrics[\"f1_per_class\"][cls_idx].item()\n",
        "    spec = last_train_metrics[\"specificity_per_class\"][cls_idx].item()\n",
        "    mse = last_train_metrics[\"mse_per_class\"][cls_idx].item()\n",
        "    mae = last_train_metrics[\"mae_per_class\"][cls_idx].item()\n",
        "    r2 = last_train_metrics[\"r2_per_class\"][cls_idx].item()\n",
        "\n",
        "    train_last_per_class_metrics[class_name] = {\n",
        "        \"accuracy\": acc if not math.isnan(acc) else 0.0,\n",
        "        \"precision\": prec if not math.isnan(prec) else 0.0,\n",
        "        \"recall\": rec if not math.isnan(rec) else 0.0,\n",
        "        \"f1_score\": f1 if not math.isnan(f1) else 0.0,\n",
        "        \"specificity\": spec if not math.isnan(spec) else 0.0,\n",
        "        \"mse\": mse if not math.isnan(mse) else 0.0,\n",
        "        \"mae\": mae if not math.isnan(mae) else 0.0,\n",
        "        \"r2\": r2 if not math.isnan(r2) else 0.0,\n",
        "    }\n",
        "test_last_log[\"train_last/per_class_metrics\"] = train_last_per_class_metrics\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(\"=== TEST RESULTS LAST MODEL ===\")\n",
        "print(\n",
        "    f\"Test | Loss {test_last_stats['loss']:.4f}, \"\n",
        "    f\"Acc_macro {test_last_stats['accuracy_macro']:.4f}, \"\n",
        "    f\"Acc_global {test_last_stats['accuracy_global']:.4f}, \"\n",
        "    f\"Prec_macro {test_last_stats['precision_macro']:.4f}, \"\n",
        "    f\"Rec_macro {test_last_stats['recall_macro']:.4f}, \"\n",
        "    f\"F1_macro {test_last_stats['f1_macro']:.4f}, \"\n",
        "    f\"Spec_macro {test_last_stats['specificity_macro']:.4f}\"\n",
        ")\n",
        "\n",
        "print(\"\\nPer-Class Classification Metrics:\")\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = test_last_stats[\"accuracy_per_class\"][cls_idx]\n",
        "    p = test_last_stats[\"precision_per_class\"][cls_idx]\n",
        "    r = test_last_stats[\"recall_per_class\"][cls_idx]\n",
        "    f = test_last_stats[\"f1_per_class\"][cls_idx]\n",
        "    s = test_last_stats[\"specificity_per_class\"][cls_idx]\n",
        "    print(f\"  Class {class_name:<12}: Acc {acc:.4f}, Prec {p:.4f}, Rec {r:.4f}, F1 {f:.4f}, Spec {s:.4f}\")\n",
        "\n",
        "print(\"\\nMacro Regression Metrics:\")\n",
        "print(\n",
        "    f\"  MSE_macro {test_last_stats['mse_macro']:.4f}, \"\n",
        "    f\"MAE_macro {test_last_stats['mae_macro']:.4f}, \"\n",
        "    f\"R2_macro {test_last_stats['r2_macro']:.4f}\"\n",
        ")\n",
        "\n",
        "print(\"\\nPer-Class Regression Metrics (MSE, MAE, R2):\")\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    mse = test_last_stats[\"mse_per_class\"][cls_idx]\n",
        "    mae = test_last_stats[\"mae_per_class\"][cls_idx]\n",
        "    r2 = test_last_stats[\"r2_per_class\"][cls_idx]\n",
        "    if r2 == 0.0 and test_last_stats[\"mse_per_class\"][cls_idx] > 0.0001:\n",
        "        print(f\"  Class {class_name:<12}: MSE {mse:.4f}, MAE {mae:.4f}, R2 {r2:.4f} (R2=0 likely due to zero target variance)\")\n",
        "    else:\n",
        "        print(f\"  Class {class_name:<12}: MSE {mse:.4f}, MAE {mae:.4f}, R2 {r2:.4f}\")\n",
        "\n",
        "wandb.log({\n",
        "    \"test/confusion_matrix_last_model\": wandb.plot.confusion_matrix(\n",
        "        preds=test_last_stats[\"raw_classification_preds\"],\n",
        "        y_true=test_last_stats[\"raw_classification_targets\"],\n",
        "        class_names=CLASS_NAMES\n",
        "    )\n",
        "})\n",
        "\n",
        "# --- W&B Artifact Logging (updated metadata) ---\n",
        "last_art = wandb.Artifact(\"repvgg-last\", type=\"model\")\n",
        "last_art.add_file(LAST_PATH)\n",
        "last_art.add_file(LAST_PTH)\n",
        "last_art.metadata.update(test_last_log)\n",
        "last_art.metadata.update({\"opset\": 17})\n",
        "logged_last = wandb.log_artifact(last_art, aliases=[\"last\"])\n",
        "logged_last.wait()\n",
        "print(f\"Model saved and pushed to W&B : {wandb.run.get_url()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:43:06.095129Z",
          "iopub.status.busy": "2025-06-22T15:43:06.094891Z",
          "iopub.status.idle": "2025-06-22T15:43:06.148916Z",
          "shell.execute_reply": "2025-06-22T15:43:06.148402Z",
          "shell.execute_reply.started": "2025-06-22T15:43:06.095103Z"
        },
        "trusted": true,
        "id": "5FGCPOWVfYDG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:43:06.150000Z",
          "iopub.status.busy": "2025-06-22T15:43:06.149735Z",
          "iopub.status.idle": "2025-06-22T15:43:19.710814Z",
          "shell.execute_reply": "2025-06-22T15:43:19.710225Z",
          "shell.execute_reply.started": "2025-06-22T15:43:06.149957Z"
        },
        "trusted": true,
        "id": "JIMjG-rFfYDH",
        "outputId": "e2ba2642-fad0-4166-b9b0-6ddfbe068348"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/3595078229.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(BEST_PTH, map_location=DEVICE)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "=== TEST RESULTS BEST MODEL ===\n",
            "Test | Loss 3.6584, Acc_macro 0.7306, Acc_global 0.8427, Prec_macro 0.6698, Rec_macro 0.7306, F1_macro 0.6851, Spec_macro 0.9844\n",
            "\n",
            "Per-Class Classification Metrics:\n",
            "  Class AC          : Acc 0.7500, Prec 0.5455, Rec 0.7500, F1 0.6316, Spec 0.9954\n",
            "  Class Ambiguous   : Acc 0.8969, Prec 0.9607, Rec 0.8969, F1 0.9277, Spec 0.9602\n",
            "  Class TA          : Acc 0.7292, Prec 0.8333, Rec 0.7292, F1 0.7778, Spec 0.9861\n",
            "  Class SA          : Acc 0.9524, Prec 0.8000, Rec 0.9524, F1 0.8696, Spec 0.9692\n",
            "  Class TAUL_TARL   : Acc 0.9091, Prec 0.6579, Rec 0.9091, F1 0.7634, Spec 0.9751\n",
            "  Class UL_RL       : Acc 0.7232, Prec 0.7570, Rec 0.7232, F1 0.7397, Spec 0.9737\n",
            "  Class SW          : Acc 0.6538, Prec 0.5312, Rec 0.6538, F1 0.5862, Spec 0.9860\n",
            "  Class TCW         : Acc 0.8333, Prec 0.3333, Rec 0.8333, F1 0.4762, Spec 0.9909\n",
            "  Class UPE_RPE     : Acc 0.7857, Prec 0.7674, Rec 0.7857, F1 0.7765, Spec 0.9905\n",
            "  Class DL          : Acc 0.4783, Prec 0.6471, Rec 0.4783, F1 0.5500, Spec 0.9944\n",
            "  Class ESW         : Acc 0.6552, Prec 0.7037, Rec 0.6552, F1 0.6786, Spec 0.9925\n",
            "  Class ECW         : Acc 0.4000, Prec 0.5000, Rec 0.4000, F1 0.4444, Spec 0.9982\n",
            "\n",
            "Macro Regression Metrics:\n",
            "  MSE_macro 6.8478, MAE_macro 1.6554, R2_macro 0.0436\n",
            "\n",
            "Per-Class Regression Metrics (MSE, MAE, R2):\n",
            "  Class AC          : MSE 1.1111, MAE 0.6874, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class Ambiguous   : MSE 6.8766, MAE 1.2698, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class TA          : MSE 0.4298, MAE 0.4434, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class SA          : MSE 0.2259, MAE 0.3429, R2 0.0000 (R2=0 likely due to zero target variance)\n",
            "  Class TAUL_TARL   : MSE 2.3788, MAE 1.2094, R2 -0.1595\n",
            "  Class UL_RL       : MSE 17.4940, MAE 3.3150, R2 -0.7100\n",
            "  Class SW          : MSE 6.5448, MAE 1.8949, R2 0.6852\n",
            "  Class TCW         : MSE 9.0876, MAE 2.2936, R2 -1.1957\n",
            "  Class UPE_RPE     : MSE 11.1449, MAE 2.2254, R2 0.3775\n",
            "  Class DL          : MSE 15.5257, MAE 2.7539, R2 0.7265\n",
            "  Class ESW         : MSE 9.7990, MAE 2.3525, R2 0.4937\n",
            "  Class ECW         : MSE 1.5550, MAE 1.0767, R2 0.3058\n",
            "Model saved and pushed to W&B : https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "repvgg_best = RepVGGMultiTask(num_classes=NUM_CLASSES, dropout_rate=0.5).to(DEVICE)\n",
        "\n",
        "checkpoint = torch.load(BEST_PTH, map_location=DEVICE)\n",
        "\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in checkpoint.items():\n",
        "    name = k[7:] if k.startswith('module.') else k\n",
        "    new_state_dict[name] = v\n",
        "\n",
        "repvgg_best.load_state_dict(new_state_dict)\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"Using {torch.cuda.device_count()} GPUs for best model evaluation.\")\n",
        "    repvgg_best = nn.DataParallel(repvgg_best)\n",
        "repvgg_best.to(DEVICE)\n",
        "repvgg_best.eval()\n",
        "\n",
        "test_best_stats = run_epoch(repvgg_best, test_loader, train=False, optimizer=None, criterion_cls=classification_loss_fn, criterion_reg=regression_loss_fn, DEVICE=DEVICE, NUM_CLASSES=NUM_CLASSES, REG_IMPORTANCE=REG_IMPORTANCE)\n",
        "\n",
        "# Compose best_test_log for W&B artifact metadata (Macro/aggregate metrics)\n",
        "best_test_log = {\n",
        "    \"test/loss\": test_best_stats[\"loss\"],\n",
        "    \"test/accuracy_macro\": test_best_stats[\"accuracy_macro\"],\n",
        "    \"test/accuracy_global\": test_best_stats[\"accuracy_global\"],\n",
        "    \"test/precision_macro\": test_best_stats[\"precision_macro\"],\n",
        "    \"test/recall_macro\": test_best_stats[\"recall_macro\"],\n",
        "    \"test/f1_macro\": test_best_stats[\"f1_macro\"],\n",
        "    \"test/specificity_macro\": test_best_stats[\"specificity_macro\"],\n",
        "    \"test/mse_macro\": test_best_stats[\"mse_macro\"],\n",
        "    \"test/mae_macro\": test_best_stats[\"mae_macro\"],\n",
        "    \"test/r2_macro\": test_best_stats[\"r2_macro\"],\n",
        "    \"epochs_trained\": best_epoch_num # Log epoch number for best model\n",
        "}\n",
        "\n",
        "# Add per-class metrics as a nested dictionary to the artifact metadata for the best model (TEST)\n",
        "test_best_per_class_metrics = {}\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = test_best_stats[\"accuracy_per_class\"][cls_idx].item()\n",
        "    prec = test_best_stats[\"precision_per_class\"][cls_idx].item()\n",
        "    rec = test_best_stats[\"recall_per_class\"][cls_idx].item()\n",
        "    f1 = test_best_stats[\"f1_per_class\"][cls_idx].item()\n",
        "    spec = test_best_stats[\"specificity_per_class\"][cls_idx].item()\n",
        "    mse = test_best_stats[\"mse_per_class\"][cls_idx].item()\n",
        "    mae = test_best_stats[\"mae_per_class\"][cls_idx].item()\n",
        "    r2 = test_best_stats[\"r2_per_class\"][cls_idx].item()\n",
        "\n",
        "    test_best_per_class_metrics[class_name] = {\n",
        "        \"accuracy\": acc if not math.isnan(acc) else 0.0,\n",
        "        \"precision\": prec if not math.isnan(prec) else 0.0,\n",
        "        \"recall\": rec if not math.isnan(rec) else 0.0,\n",
        "        \"f1_score\": f1 if not math.isnan(f1) else 0.0,\n",
        "        \"specificity\": spec if not math.isnan(spec) else 0.0,\n",
        "        \"mse\": mse if not math.isnan(mse) else 0.0,\n",
        "        \"mae\": mae if not math.isnan(mae) else 0.0,\n",
        "        \"r2\": r2 if not math.isnan(r2) else 0.0,\n",
        "    }\n",
        "best_test_log[\"test/per_class_metrics\"] = test_best_per_class_metrics\n",
        "\n",
        "\n",
        "# Include BEST validation macro metrics in the artifact metadata\n",
        "best_test_log.update({\n",
        "    \"val_best/loss\": best_metrics[\"loss\"],\n",
        "    \"val_best/accuracy_macro\": best_metrics[\"accuracy_macro\"],\n",
        "    \"val_best/accuracy_global\": best_metrics[\"accuracy_global\"],\n",
        "    \"val_best/precision_macro\": best_metrics[\"precision_macro\"],\n",
        "    \"val_best/recall_macro\": best_metrics[\"recall_macro\"],\n",
        "    \"val_best/f1_macro\": best_metrics[\"f1_macro\"],\n",
        "    \"val_best/specificity_macro\": best_metrics[\"specificity_macro\"],\n",
        "    \"val_best/mse_macro\": best_metrics[\"mse_macro\"],\n",
        "    \"val_best/mae_macro\": best_metrics[\"mae_macro\"],\n",
        "    \"val_best/r2_macro\": best_metrics[\"r2_macro\"],\n",
        "})\n",
        "\n",
        "# Add per-class metrics as a nested dictionary to the artifact metadata for the best model (VAL)\n",
        "val_best_per_class_metrics = {}\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = best_metrics[\"accuracy_per_class\"][cls_idx].item()\n",
        "    prec = best_metrics[\"precision_per_class\"][cls_idx].item()\n",
        "    rec = best_metrics[\"recall_per_class\"][cls_idx].item()\n",
        "    f1 = best_metrics[\"f1_per_class\"][cls_idx].item()\n",
        "    spec = best_metrics[\"specificity_per_class\"][cls_idx].item()\n",
        "    mse = best_metrics[\"mse_per_class\"][cls_idx].item()\n",
        "    mae = best_metrics[\"mae_per_class\"][cls_idx].item()\n",
        "    r2 = best_metrics[\"r2_per_class\"][cls_idx].item()\n",
        "\n",
        "    val_best_per_class_metrics[class_name] = {\n",
        "        \"accuracy\": acc if not math.isnan(acc) else 0.0,\n",
        "        \"precision\": prec if not math.isnan(prec) else 0.0,\n",
        "        \"recall\": rec if not math.isnan(rec) else 0.0,\n",
        "        \"f1_score\": f1 if not math.isnan(f1) else 0.0,\n",
        "        \"specificity\": spec if not math.isnan(spec) else 0.0,\n",
        "        \"mse\": mse if not math.isnan(mse) else 0.0,\n",
        "        \"mae\": mae if not math.isnan(mae) else 0.0,\n",
        "        \"r2\": r2 if not math.isnan(r2) else 0.0,\n",
        "    }\n",
        "best_test_log[\"val_best/per_class_metrics\"] = val_best_per_class_metrics\n",
        "\n",
        "# Include BEST training macro metrics in the artifact metadata\n",
        "best_test_log.update({\n",
        "    \"train_best/loss\": best_train_metrics[\"loss\"],\n",
        "    \"train_best/accuracy_macro\": best_train_metrics[\"accuracy_macro\"],\n",
        "    \"train_best/accuracy_global\": best_train_metrics[\"accuracy_global\"],\n",
        "    \"train_best/precision_macro\": best_train_metrics[\"precision_macro\"],\n",
        "    \"train_best/recall_macro\": best_train_metrics[\"recall_macro\"],\n",
        "    \"train_best/f1_macro\": best_train_metrics[\"f1_macro\"],\n",
        "    \"train_best/specificity_macro\": best_train_metrics[\"specificity_macro\"],\n",
        "    \"train_best/mse_macro\": best_train_metrics[\"mse_macro\"],\n",
        "    \"train_best/mae_macro\": best_train_metrics[\"mae_macro\"],\n",
        "    \"train_best/r2_macro\": best_train_metrics[\"r2_macro\"],\n",
        "})\n",
        "\n",
        "# Add per-class metrics as a nested dictionary to the artifact metadata for the best model (TRAIN)\n",
        "train_best_per_class_metrics = {}\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = best_train_metrics[\"accuracy_per_class\"][cls_idx].item()\n",
        "    prec = best_train_metrics[\"precision_per_class\"][cls_idx].item()\n",
        "    rec = best_train_metrics[\"recall_per_class\"][cls_idx].item()\n",
        "    f1 = best_train_metrics[\"f1_per_class\"][cls_idx].item()\n",
        "    spec = best_train_metrics[\"specificity_per_class\"][cls_idx].item()\n",
        "    mse = best_train_metrics[\"mse_per_class\"][cls_idx].item()\n",
        "    mae = best_train_metrics[\"mae_per_class\"][cls_idx].item()\n",
        "    r2 = best_train_metrics[\"r2_per_class\"][cls_idx].item()\n",
        "\n",
        "    train_best_per_class_metrics[class_name] = {\n",
        "        \"accuracy\": acc if not math.isnan(acc) else 0.0,\n",
        "        \"precision\": prec if not math.isnan(prec) else 0.0,\n",
        "        \"recall\": rec if not math.isnan(rec) else 0.0,\n",
        "        \"f1_score\": f1 if not math.isnan(f1) else 0.0,\n",
        "        \"specificity\": spec if not math.isnan(spec) else 0.0,\n",
        "        \"mse\": mse if not math.isnan(mse) else 0.0,\n",
        "        \"mae\": mae if not math.isnan(mae) else 0.0,\n",
        "        \"r2\": r2 if not math.isnan(r2) else 0.0,\n",
        "    }\n",
        "best_test_log[\"train_best/per_class_metrics\"] = train_best_per_class_metrics\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(\"=== TEST RESULTS BEST MODEL ===\")\n",
        "print(\n",
        "    f\"Test | Loss {test_best_stats['loss']:.4f}, \"\n",
        "    f\"Acc_macro {test_best_stats['accuracy_macro']:.4f}, \"\n",
        "    f\"Acc_global {test_best_stats['accuracy_global']:.4f}, \"\n",
        "    f\"Prec_macro {test_best_stats['precision_macro']:.4f}, \"\n",
        "    f\"Rec_macro {test_best_stats['recall_macro']:.4f}, \"\n",
        "    f\"F1_macro {test_best_stats['f1_macro']:.4f}, \"\n",
        "    f\"Spec_macro {test_best_stats['specificity_macro']:.4f}\"\n",
        ")\n",
        "\n",
        "print(\"\\nPer-Class Classification Metrics:\")\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    acc = test_best_stats[\"accuracy_per_class\"][cls_idx]\n",
        "    p = test_best_stats[\"precision_per_class\"][cls_idx]\n",
        "    r = test_best_stats[\"recall_per_class\"][cls_idx]\n",
        "    f = test_best_stats[\"f1_per_class\"][cls_idx]\n",
        "    s = test_best_stats[\"specificity_per_class\"][cls_idx]\n",
        "    print(f\"  Class {class_name:<12}: Acc {acc:.4f}, Prec {p:.4f}, Rec {r:.4f}, F1 {f:.4f}, Spec {s:.4f}\")\n",
        "\n",
        "print(\"\\nMacro Regression Metrics:\")\n",
        "print(\n",
        "    f\"  MSE_macro {test_best_stats['mse_macro']:.4f}, \"\n",
        "    f\"MAE_macro {test_best_stats['mae_macro']:.4f}, \"\n",
        "    f\"R2_macro {test_best_stats['r2_macro']:.4f}\"\n",
        ")\n",
        "\n",
        "print(\"\\nPer-Class Regression Metrics (MSE, MAE, R2):\")\n",
        "for cls_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    mse = test_best_stats[\"mse_per_class\"][cls_idx]\n",
        "    mae = test_best_stats[\"mae_per_class\"][cls_idx]\n",
        "    r2 = test_best_stats[\"r2_per_class\"][cls_idx]\n",
        "    if r2 == 0.0 and test_best_stats[\"mse_per_class\"][cls_idx] > 0.0001:\n",
        "        print(f\"  Class {class_name:<12}: MSE {mse:.4f}, MAE {mae:.4f}, R2 {r2:.4f} (R2=0 likely due to zero target variance)\")\n",
        "    else:\n",
        "        print(f\"  Class {class_name:<12}: MSE {mse:.4f}, MAE {mae:.4f}, R2 {r2:.4f}\")\n",
        "\n",
        "wandb.log({\n",
        "    \"test/confusion_matrix_best_model\": wandb.plot.confusion_matrix(\n",
        "        preds=test_best_stats[\"raw_classification_preds\"],\n",
        "        y_true=test_best_stats[\"raw_classification_targets\"],\n",
        "        class_names=CLASS_NAMES\n",
        "    )\n",
        "})\n",
        "\n",
        "# --- W&B Artifact Logging (updated metadata) ---\n",
        "best_art = wandb.Artifact(\"repvgg-best\", type=\"model\")\n",
        "best_art.add_file(BEST_PATH)\n",
        "best_art.add_file(BEST_PTH)\n",
        "best_art.metadata.update(best_test_log)\n",
        "best_art.metadata.update({\"opset\": 17})\n",
        "logged_best = wandb.log_artifact(best_art, aliases=[\"best\"])\n",
        "logged_best.wait()\n",
        "print(f\"Model saved and pushed to W&B : {wandb.run.get_url()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-22T15:43:19.712021Z",
          "iopub.status.busy": "2025-06-22T15:43:19.711720Z",
          "iopub.status.idle": "2025-06-22T15:43:21.284156Z",
          "shell.execute_reply": "2025-06-22T15:43:21.283401Z",
          "shell.execute_reply.started": "2025-06-22T15:43:19.711993Z"
        },
        "trusted": true,
        "id": "YDc7uOU3fYDM",
        "outputId": "e4cc93e2-6382-431d-c72a-926f87249bbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>train/accuracy_AC</td><td>▁█</td></tr><tr><td>train/accuracy_Ambiguous</td><td>▁█</td></tr><tr><td>train/accuracy_DL</td><td>▁█</td></tr><tr><td>train/accuracy_ECW</td><td>▁█</td></tr><tr><td>train/accuracy_ESW</td><td>▁█</td></tr><tr><td>train/accuracy_SA</td><td>▁█</td></tr><tr><td>train/accuracy_SW</td><td>▁█</td></tr><tr><td>train/accuracy_TA</td><td>▁█</td></tr><tr><td>train/accuracy_TAUL_TARL</td><td>▁█</td></tr><tr><td>train/accuracy_TCW</td><td>▁█</td></tr><tr><td>train/accuracy_UL_RL</td><td>▁█</td></tr><tr><td>train/accuracy_UPE_RPE</td><td>▁█</td></tr><tr><td>train/accuracy_global</td><td>▁█</td></tr><tr><td>train/accuracy_macro</td><td>▁█</td></tr><tr><td>train/f1_AC</td><td>▁█</td></tr><tr><td>train/f1_Ambiguous</td><td>▁█</td></tr><tr><td>train/f1_DL</td><td>▁█</td></tr><tr><td>train/f1_ECW</td><td>▁█</td></tr><tr><td>train/f1_ESW</td><td>▁█</td></tr><tr><td>train/f1_SA</td><td>▁█</td></tr><tr><td>train/f1_SW</td><td>▁█</td></tr><tr><td>train/f1_TA</td><td>▁█</td></tr><tr><td>train/f1_TAUL_TARL</td><td>▁█</td></tr><tr><td>train/f1_TCW</td><td>▁█</td></tr><tr><td>train/f1_UL_RL</td><td>▁█</td></tr><tr><td>train/f1_UPE_RPE</td><td>▁█</td></tr><tr><td>train/f1_macro</td><td>▁█</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/mae_AC</td><td>█▁</td></tr><tr><td>train/mae_Ambiguous</td><td>█▁</td></tr><tr><td>train/mae_DL</td><td>█▁</td></tr><tr><td>train/mae_ECW</td><td>█▁</td></tr><tr><td>train/mae_ESW</td><td>█▁</td></tr><tr><td>train/mae_SA</td><td>█▁</td></tr><tr><td>train/mae_SW</td><td>█▁</td></tr><tr><td>train/mae_TA</td><td>█▁</td></tr><tr><td>train/mae_TAUL_TARL</td><td>█▁</td></tr><tr><td>train/mae_TCW</td><td>█▁</td></tr><tr><td>train/mae_UL_RL</td><td>█▁</td></tr><tr><td>train/mae_UPE_RPE</td><td>█▁</td></tr><tr><td>train/mae_macro</td><td>█▁</td></tr><tr><td>train/mse_AC</td><td>█▁</td></tr><tr><td>train/mse_Ambiguous</td><td>█▁</td></tr><tr><td>train/mse_DL</td><td>█▁</td></tr><tr><td>train/mse_ECW</td><td>█▁</td></tr><tr><td>train/mse_ESW</td><td>█▁</td></tr><tr><td>train/mse_SA</td><td>█▁</td></tr><tr><td>train/mse_SW</td><td>█▁</td></tr><tr><td>train/mse_TA</td><td>█▁</td></tr><tr><td>train/mse_TAUL_TARL</td><td>█▁</td></tr><tr><td>train/mse_TCW</td><td>█▁</td></tr><tr><td>train/mse_UL_RL</td><td>█▁</td></tr><tr><td>train/mse_UPE_RPE</td><td>█▁</td></tr><tr><td>train/mse_macro</td><td>█▁</td></tr><tr><td>train/precision_AC</td><td>▁█</td></tr><tr><td>train/precision_Ambiguous</td><td>▁█</td></tr><tr><td>train/precision_DL</td><td>▁█</td></tr><tr><td>train/precision_ECW</td><td>▁█</td></tr><tr><td>train/precision_ESW</td><td>▁█</td></tr><tr><td>train/precision_SA</td><td>▁█</td></tr><tr><td>train/precision_SW</td><td>▁█</td></tr><tr><td>train/precision_TA</td><td>▁█</td></tr><tr><td>train/precision_TAUL_TARL</td><td>▁█</td></tr><tr><td>train/precision_TCW</td><td>▁█</td></tr><tr><td>train/precision_UL_RL</td><td>▁█</td></tr><tr><td>train/precision_UPE_RPE</td><td>▁█</td></tr><tr><td>train/precision_macro</td><td>▁█</td></tr><tr><td>train/r2_AC</td><td>▁▁</td></tr><tr><td>train/r2_Ambiguous</td><td>▁▁</td></tr><tr><td>train/r2_DL</td><td>▁█</td></tr><tr><td>train/r2_ECW</td><td>▁█</td></tr><tr><td>train/r2_ESW</td><td>▁█</td></tr><tr><td>train/r2_SA</td><td>▁▁</td></tr><tr><td>train/r2_SW</td><td>▁█</td></tr><tr><td>train/r2_TA</td><td>▁▁</td></tr><tr><td>train/r2_TAUL_TARL</td><td>▁█</td></tr><tr><td>train/r2_TCW</td><td>▁█</td></tr><tr><td>train/r2_UL_RL</td><td>▁█</td></tr><tr><td>train/r2_UPE_RPE</td><td>▁█</td></tr><tr><td>train/r2_macro</td><td>▁█</td></tr><tr><td>train/recall_AC</td><td>▁█</td></tr><tr><td>train/recall_Ambiguous</td><td>▁█</td></tr><tr><td>train/recall_DL</td><td>▁█</td></tr><tr><td>train/recall_ECW</td><td>▁█</td></tr><tr><td>train/recall_ESW</td><td>▁█</td></tr><tr><td>train/recall_SA</td><td>▁█</td></tr><tr><td>train/recall_SW</td><td>▁█</td></tr><tr><td>train/recall_TA</td><td>▁█</td></tr><tr><td>train/recall_TAUL_TARL</td><td>▁█</td></tr><tr><td>train/recall_TCW</td><td>▁█</td></tr><tr><td>train/recall_UL_RL</td><td>▁█</td></tr><tr><td>train/recall_UPE_RPE</td><td>▁█</td></tr><tr><td>train/recall_macro</td><td>▁█</td></tr><tr><td>train/specificity_AC</td><td>▁█</td></tr><tr><td>train/specificity_Ambiguous</td><td>▁█</td></tr><tr><td>train/specificity_DL</td><td>▁█</td></tr><tr><td>train/specificity_ECW</td><td>▁█</td></tr><tr><td>train/specificity_ESW</td><td>▁█</td></tr><tr><td>train/specificity_SA</td><td>▁█</td></tr><tr><td>train/specificity_SW</td><td>▁█</td></tr><tr><td>train/specificity_TA</td><td>▁█</td></tr><tr><td>train/specificity_TAUL_TARL</td><td>▁█</td></tr><tr><td>train/specificity_TCW</td><td>▁█</td></tr><tr><td>train/specificity_UL_RL</td><td>▁█</td></tr><tr><td>train/specificity_UPE_RPE</td><td>▁█</td></tr><tr><td>train/specificity_macro</td><td>▁█</td></tr><tr><td>val/accuracy_AC</td><td>▁█</td></tr><tr><td>val/accuracy_Ambiguous</td><td>█▁</td></tr><tr><td>val/accuracy_DL</td><td>▁▁</td></tr><tr><td>val/accuracy_ECW</td><td>▁█</td></tr><tr><td>val/accuracy_ESW</td><td>▁█</td></tr><tr><td>val/accuracy_SA</td><td>▁█</td></tr><tr><td>val/accuracy_SW</td><td>█▁</td></tr><tr><td>val/accuracy_TA</td><td>▁█</td></tr><tr><td>val/accuracy_TAUL_TARL</td><td>█▁</td></tr><tr><td>val/accuracy_TCW</td><td>▁█</td></tr><tr><td>val/accuracy_UL_RL</td><td>█▁</td></tr><tr><td>val/accuracy_UPE_RPE</td><td>▁█</td></tr><tr><td>val/accuracy_global</td><td>▁█</td></tr><tr><td>val/accuracy_macro</td><td>▁█</td></tr><tr><td>val/f1_AC</td><td>█▁</td></tr><tr><td>val/f1_Ambiguous</td><td>█▁</td></tr><tr><td>val/f1_DL</td><td>▁█</td></tr><tr><td>val/f1_ECW</td><td>▁█</td></tr><tr><td>val/f1_ESW</td><td>▁█</td></tr><tr><td>val/f1_SA</td><td>▁█</td></tr><tr><td>val/f1_SW</td><td>▁█</td></tr><tr><td>val/f1_TA</td><td>▁█</td></tr><tr><td>val/f1_TAUL_TARL</td><td>█▁</td></tr><tr><td>val/f1_TCW</td><td>▁█</td></tr><tr><td>val/f1_UL_RL</td><td>█▁</td></tr><tr><td>val/f1_UPE_RPE</td><td>▁█</td></tr><tr><td>val/f1_macro</td><td>▁█</td></tr><tr><td>val/loss</td><td>█▁</td></tr><tr><td>val/mae_AC</td><td>█▁</td></tr><tr><td>val/mae_Ambiguous</td><td>█▁</td></tr><tr><td>val/mae_DL</td><td>▁█</td></tr><tr><td>val/mae_ECW</td><td>█▁</td></tr><tr><td>val/mae_ESW</td><td>▁█</td></tr><tr><td>val/mae_SA</td><td>█▁</td></tr><tr><td>val/mae_SW</td><td>▁█</td></tr><tr><td>val/mae_TA</td><td>█▁</td></tr><tr><td>val/mae_TAUL_TARL</td><td>▁█</td></tr><tr><td>val/mae_TCW</td><td>▁█</td></tr><tr><td>val/mae_UL_RL</td><td>▁█</td></tr><tr><td>val/mae_UPE_RPE</td><td>▁█</td></tr><tr><td>val/mae_macro</td><td>▁█</td></tr><tr><td>val/mse_AC</td><td>█▁</td></tr><tr><td>val/mse_Ambiguous</td><td>█▁</td></tr><tr><td>val/mse_DL</td><td>█▁</td></tr><tr><td>val/mse_ECW</td><td>█▁</td></tr><tr><td>val/mse_ESW</td><td>▁█</td></tr><tr><td>val/mse_SA</td><td>█▁</td></tr><tr><td>val/mse_SW</td><td>▁█</td></tr><tr><td>val/mse_TA</td><td>█▁</td></tr><tr><td>val/mse_TAUL_TARL</td><td>▁█</td></tr><tr><td>val/mse_TCW</td><td>▁█</td></tr><tr><td>val/mse_UL_RL</td><td>▁█</td></tr><tr><td>val/mse_UPE_RPE</td><td>▁█</td></tr><tr><td>val/mse_macro</td><td>▁█</td></tr><tr><td>val/precision_AC</td><td>█▁</td></tr><tr><td>val/precision_Ambiguous</td><td>█▁</td></tr><tr><td>val/precision_DL</td><td>▁█</td></tr><tr><td>val/precision_ECW</td><td>▁█</td></tr><tr><td>val/precision_ESW</td><td>▁█</td></tr><tr><td>val/precision_SA</td><td>▁█</td></tr><tr><td>val/precision_SW</td><td>▁█</td></tr><tr><td>val/precision_TA</td><td>█▁</td></tr><tr><td>val/precision_TAUL_TARL</td><td>█▁</td></tr><tr><td>val/precision_TCW</td><td>▁█</td></tr><tr><td>val/precision_UL_RL</td><td>▁█</td></tr><tr><td>val/precision_UPE_RPE</td><td>█▁</td></tr><tr><td>val/precision_macro</td><td>▁█</td></tr><tr><td>val/r2_AC</td><td>▁▁</td></tr><tr><td>val/r2_Ambiguous</td><td>▁▁</td></tr><tr><td>val/r2_DL</td><td>▁█</td></tr><tr><td>val/r2_ECW</td><td>▁█</td></tr><tr><td>val/r2_ESW</td><td>█▁</td></tr><tr><td>val/r2_SA</td><td>▁▁</td></tr><tr><td>val/r2_SW</td><td>█▁</td></tr><tr><td>val/r2_TA</td><td>▁▁</td></tr><tr><td>val/r2_TAUL_TARL</td><td>█▁</td></tr><tr><td>val/r2_TCW</td><td>█▁</td></tr><tr><td>val/r2_UL_RL</td><td>█▁</td></tr><tr><td>val/r2_UPE_RPE</td><td>█▁</td></tr><tr><td>val/r2_macro</td><td>█▁</td></tr><tr><td>val/recall_AC</td><td>▁█</td></tr><tr><td>val/recall_Ambiguous</td><td>█▁</td></tr><tr><td>val/recall_DL</td><td>▁▁</td></tr><tr><td>val/recall_ECW</td><td>▁█</td></tr><tr><td>val/recall_ESW</td><td>▁█</td></tr><tr><td>val/recall_SA</td><td>▁█</td></tr><tr><td>val/recall_SW</td><td>█▁</td></tr><tr><td>val/recall_TA</td><td>▁█</td></tr><tr><td>val/recall_TAUL_TARL</td><td>█▁</td></tr><tr><td>val/recall_TCW</td><td>▁█</td></tr><tr><td>val/recall_UL_RL</td><td>█▁</td></tr><tr><td>val/recall_UPE_RPE</td><td>▁█</td></tr><tr><td>val/recall_macro</td><td>▁█</td></tr><tr><td>val/specificity_AC</td><td>█▁</td></tr><tr><td>val/specificity_Ambiguous</td><td>▁▁</td></tr><tr><td>val/specificity_DL</td><td>▁█</td></tr><tr><td>val/specificity_ECW</td><td>▁█</td></tr><tr><td>val/specificity_ESW</td><td>█▁</td></tr><tr><td>val/specificity_SA</td><td>▁█</td></tr><tr><td>val/specificity_SW</td><td>▁█</td></tr><tr><td>val/specificity_TA</td><td>█▁</td></tr><tr><td>val/specificity_TAUL_TARL</td><td>█▁</td></tr><tr><td>val/specificity_TCW</td><td>▁█</td></tr><tr><td>val/specificity_UL_RL</td><td>▁█</td></tr><tr><td>val/specificity_UPE_RPE</td><td>█▁</td></tr><tr><td>val/specificity_macro</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train/accuracy_AC</td><td>0.96924</td></tr><tr><td>train/accuracy_Ambiguous</td><td>0.8305</td></tr><tr><td>train/accuracy_DL</td><td>0.70608</td></tr><tr><td>train/accuracy_ECW</td><td>0.57658</td></tr><tr><td>train/accuracy_ESW</td><td>0.50051</td></tr><tr><td>train/accuracy_SA</td><td>0.79693</td></tr><tr><td>train/accuracy_SW</td><td>0.44439</td></tr><tr><td>train/accuracy_TA</td><td>0.74323</td></tr><tr><td>train/accuracy_TAUL_TARL</td><td>0.82819</td></tr><tr><td>train/accuracy_TCW</td><td>0.72291</td></tr><tr><td>train/accuracy_UL_RL</td><td>0.85111</td></tr><tr><td>train/accuracy_UPE_RPE</td><td>0.70635</td></tr><tr><td>train/accuracy_global</td><td>0.7237</td></tr><tr><td>train/accuracy_macro</td><td>0.723</td></tr><tr><td>train/f1_AC</td><td>0.95135</td></tr><tr><td>train/f1_Ambiguous</td><td>0.82905</td></tr><tr><td>train/f1_DL</td><td>0.7137</td></tr><tr><td>train/f1_ECW</td><td>0.61943</td></tr><tr><td>train/f1_ESW</td><td>0.49735</td></tr><tr><td>train/f1_SA</td><td>0.78534</td></tr><tr><td>train/f1_SW</td><td>0.4626</td></tr><tr><td>train/f1_TA</td><td>0.7747</td></tr><tr><td>train/f1_TAUL_TARL</td><td>0.80674</td></tr><tr><td>train/f1_TCW</td><td>0.67281</td></tr><tr><td>train/f1_UL_RL</td><td>0.82472</td></tr><tr><td>train/f1_UPE_RPE</td><td>0.71847</td></tr><tr><td>train/f1_macro</td><td>0.72135</td></tr><tr><td>train/loss</td><td>2.80703</td></tr><tr><td>train/mae_AC</td><td>0.50854</td></tr><tr><td>train/mae_Ambiguous</td><td>1.87267</td></tr><tr><td>train/mae_DL</td><td>2.09087</td></tr><tr><td>train/mae_ECW</td><td>1.33011</td></tr><tr><td>train/mae_ESW</td><td>1.93649</td></tr><tr><td>train/mae_SA</td><td>0.45665</td></tr><tr><td>train/mae_SW</td><td>1.73829</td></tr><tr><td>train/mae_TA</td><td>0.56838</td></tr><tr><td>train/mae_TAUL_TARL</td><td>1.01972</td></tr><tr><td>train/mae_TCW</td><td>1.42629</td></tr><tr><td>train/mae_UL_RL</td><td>2.14029</td></tr><tr><td>train/mae_UPE_RPE</td><td>1.81579</td></tr><tr><td>train/mae_macro</td><td>1.40867</td></tr><tr><td>train/mse_AC</td><td>1.10607</td></tr><tr><td>train/mse_Ambiguous</td><td>12.81902</td></tr><tr><td>train/mse_DL</td><td>7.56321</td></tr><tr><td>train/mse_ECW</td><td>2.92755</td></tr><tr><td>train/mse_ESW</td><td>6.16591</td></tr><tr><td>train/mse_SA</td><td>0.40441</td></tr><tr><td>train/mse_SW</td><td>5.34403</td></tr><tr><td>train/mse_TA</td><td>0.80415</td></tr><tr><td>train/mse_TAUL_TARL</td><td>1.78071</td></tr><tr><td>train/mse_TCW</td><td>3.27889</td></tr><tr><td>train/mse_UL_RL</td><td>8.43973</td></tr><tr><td>train/mse_UPE_RPE</td><td>5.84975</td></tr><tr><td>train/mse_macro</td><td>4.70695</td></tr><tr><td>train/precision_AC</td><td>0.93412</td></tr><tr><td>train/precision_Ambiguous</td><td>0.8276</td></tr><tr><td>train/precision_DL</td><td>0.72149</td></tr><tr><td>train/precision_ECW</td><td>0.66915</td></tr><tr><td>train/precision_ESW</td><td>0.49424</td></tr><tr><td>train/precision_SA</td><td>0.77408</td></tr><tr><td>train/precision_SW</td><td>0.48236</td></tr><tr><td>train/precision_TA</td><td>0.80896</td></tr><tr><td>train/precision_TAUL_TARL</td><td>0.78636</td></tr><tr><td>train/precision_TCW</td><td>0.6292</td></tr><tr><td>train/precision_UL_RL</td><td>0.79992</td></tr><tr><td>train/precision_UPE_RPE</td><td>0.73101</td></tr><tr><td>train/precision_macro</td><td>0.72154</td></tr><tr><td>train/r2_AC</td><td>0</td></tr><tr><td>train/r2_Ambiguous</td><td>0</td></tr><tr><td>train/r2_DL</td><td>0.85753</td></tr><tr><td>train/r2_ECW</td><td>0.76458</td></tr><tr><td>train/r2_ESW</td><td>0.61043</td></tr><tr><td>train/r2_SA</td><td>0</td></tr><tr><td>train/r2_SW</td><td>0.76243</td></tr><tr><td>train/r2_TA</td><td>0</td></tr><tr><td>train/r2_TAUL_TARL</td><td>0.07002</td></tr><tr><td>train/r2_TCW</td><td>0.72491</td></tr><tr><td>train/r2_UL_RL</td><td>0.31786</td></tr><tr><td>train/r2_UPE_RPE</td><td>0.68968</td></tr><tr><td>train/r2_macro</td><td>0.39979</td></tr><tr><td>train/recall_AC</td><td>0.96924</td></tr><tr><td>train/recall_Ambiguous</td><td>0.8305</td></tr><tr><td>train/recall_DL</td><td>0.70608</td></tr><tr><td>train/recall_ECW</td><td>0.57658</td></tr><tr><td>train/recall_ESW</td><td>0.50051</td></tr><tr><td>train/recall_SA</td><td>0.79693</td></tr><tr><td>train/recall_SW</td><td>0.44439</td></tr><tr><td>train/recall_TA</td><td>0.74323</td></tr><tr><td>train/recall_TAUL_TARL</td><td>0.82819</td></tr><tr><td>train/recall_TCW</td><td>0.72291</td></tr><tr><td>train/recall_UL_RL</td><td>0.85111</td></tr><tr><td>train/recall_UPE_RPE</td><td>0.70635</td></tr><tr><td>train/recall_macro</td><td>0.723</td></tr><tr><td>train/specificity_AC</td><td>0.99359</td></tr><tr><td>train/specificity_Ambiguous</td><td>0.9842</td></tr><tr><td>train/specificity_DL</td><td>0.97366</td></tr><tr><td>train/specificity_ECW</td><td>0.97362</td></tr><tr><td>train/specificity_ESW</td><td>0.95399</td></tr><tr><td>train/specificity_SA</td><td>0.98226</td></tr><tr><td>train/specificity_SW</td><td>0.95718</td></tr><tr><td>train/specificity_TA</td><td>0.98467</td></tr><tr><td>train/specificity_TAUL_TARL</td><td>0.98079</td></tr><tr><td>train/specificity_TCW</td><td>0.96064</td></tr><tr><td>train/specificity_UL_RL</td><td>0.97787</td></tr><tr><td>train/specificity_UPE_RPE</td><td>0.97605</td></tr><tr><td>train/specificity_macro</td><td>0.97488</td></tr><tr><td>val/accuracy_AC</td><td>0.85714</td></tr><tr><td>val/accuracy_Ambiguous</td><td>0.85039</td></tr><tr><td>val/accuracy_DL</td><td>0.70588</td></tr><tr><td>val/accuracy_ECW</td><td>0.6</td></tr><tr><td>val/accuracy_ESW</td><td>0.8</td></tr><tr><td>val/accuracy_SA</td><td>0.95294</td></tr><tr><td>val/accuracy_SW</td><td>0.61111</td></tr><tr><td>val/accuracy_TA</td><td>0.76562</td></tr><tr><td>val/accuracy_TAUL_TARL</td><td>0.78947</td></tr><tr><td>val/accuracy_TCW</td><td>0.4</td></tr><tr><td>val/accuracy_UL_RL</td><td>0.70667</td></tr><tr><td>val/accuracy_UPE_RPE</td><td>0.7931</td></tr><tr><td>val/accuracy_global</td><td>0.81989</td></tr><tr><td>val/accuracy_macro</td><td>0.73603</td></tr><tr><td>val/f1_AC</td><td>0.52174</td></tr><tr><td>val/f1_Ambiguous</td><td>0.90629</td></tr><tr><td>val/f1_DL</td><td>0.72727</td></tr><tr><td>val/f1_ECW</td><td>0.6</td></tr><tr><td>val/f1_ESW</td><td>0.74419</td></tr><tr><td>val/f1_SA</td><td>0.84817</td></tr><tr><td>val/f1_SW</td><td>0.5641</td></tr><tr><td>val/f1_TA</td><td>0.76562</td></tr><tr><td>val/f1_TAUL_TARL</td><td>0.66667</td></tr><tr><td>val/f1_TCW</td><td>0.33333</td></tr><tr><td>val/f1_UL_RL</td><td>0.75177</td></tr><tr><td>val/f1_UPE_RPE</td><td>0.73016</td></tr><tr><td>val/f1_macro</td><td>0.67994</td></tr><tr><td>val/loss</td><td>4.86295</td></tr><tr><td>val/mae_AC</td><td>0.95242</td></tr><tr><td>val/mae_Ambiguous</td><td>1.44712</td></tr><tr><td>val/mae_DL</td><td>2.37285</td></tr><tr><td>val/mae_ECW</td><td>1.02612</td></tr><tr><td>val/mae_ESW</td><td>2.76174</td></tr><tr><td>val/mae_SA</td><td>0.34646</td></tr><tr><td>val/mae_SW</td><td>1.6357</td></tr><tr><td>val/mae_TA</td><td>0.35143</td></tr><tr><td>val/mae_TAUL_TARL</td><td>1.13351</td></tr><tr><td>val/mae_TCW</td><td>4.47795</td></tr><tr><td>val/mae_UL_RL</td><td>3.44491</td></tr><tr><td>val/mae_UPE_RPE</td><td>2.1991</td></tr><tr><td>val/mae_macro</td><td>1.84578</td></tr><tr><td>val/mse_AC</td><td>5.00625</td></tr><tr><td>val/mse_Ambiguous</td><td>10.50441</td></tr><tr><td>val/mse_DL</td><td>9.51703</td></tr><tr><td>val/mse_ECW</td><td>1.62991</td></tr><tr><td>val/mse_ESW</td><td>11.316</td></tr><tr><td>val/mse_SA</td><td>0.17619</td></tr><tr><td>val/mse_SW</td><td>4.04673</td></tr><tr><td>val/mse_TA</td><td>0.16365</td></tr><tr><td>val/mse_TAUL_TARL</td><td>2.48674</td></tr><tr><td>val/mse_TCW</td><td>34.69284</td></tr><tr><td>val/mse_UL_RL</td><td>23.27107</td></tr><tr><td>val/mse_UPE_RPE</td><td>7.84818</td></tr><tr><td>val/mse_macro</td><td>9.22158</td></tr><tr><td>val/precision_AC</td><td>0.375</td></tr><tr><td>val/precision_Ambiguous</td><td>0.97006</td></tr><tr><td>val/precision_DL</td><td>0.75</td></tr><tr><td>val/precision_ECW</td><td>0.6</td></tr><tr><td>val/precision_ESW</td><td>0.69565</td></tr><tr><td>val/precision_SA</td><td>0.76415</td></tr><tr><td>val/precision_SW</td><td>0.52381</td></tr><tr><td>val/precision_TA</td><td>0.76562</td></tr><tr><td>val/precision_TAUL_TARL</td><td>0.57692</td></tr><tr><td>val/precision_TCW</td><td>0.28571</td></tr><tr><td>val/precision_UL_RL</td><td>0.80303</td></tr><tr><td>val/precision_UPE_RPE</td><td>0.67647</td></tr><tr><td>val/precision_macro</td><td>0.64887</td></tr><tr><td>val/r2_AC</td><td>0</td></tr><tr><td>val/r2_Ambiguous</td><td>0</td></tr><tr><td>val/r2_DL</td><td>0.82986</td></tr><tr><td>val/r2_ECW</td><td>0.74533</td></tr><tr><td>val/r2_ESW</td><td>0.22705</td></tr><tr><td>val/r2_SA</td><td>0</td></tr><tr><td>val/r2_SW</td><td>0.77518</td></tr><tr><td>val/r2_TA</td><td>0</td></tr><tr><td>val/r2_TAUL_TARL</td><td>-0.67718</td></tr><tr><td>val/r2_TCW</td><td>-5.47256</td></tr><tr><td>val/r2_UL_RL</td><td>-0.46973</td></tr><tr><td>val/r2_UPE_RPE</td><td>0.50171</td></tr><tr><td>val/r2_macro</td><td>-0.29503</td></tr><tr><td>val/recall_AC</td><td>0.85714</td></tr><tr><td>val/recall_Ambiguous</td><td>0.85039</td></tr><tr><td>val/recall_DL</td><td>0.70588</td></tr><tr><td>val/recall_ECW</td><td>0.6</td></tr><tr><td>val/recall_ESW</td><td>0.8</td></tr><tr><td>val/recall_SA</td><td>0.95294</td></tr><tr><td>val/recall_SW</td><td>0.61111</td></tr><tr><td>val/recall_TA</td><td>0.76562</td></tr><tr><td>val/recall_TAUL_TARL</td><td>0.78947</td></tr><tr><td>val/recall_TCW</td><td>0.4</td></tr><tr><td>val/recall_UL_RL</td><td>0.70667</td></tr><tr><td>val/recall_UPE_RPE</td><td>0.7931</td></tr><tr><td>val/recall_macro</td><td>0.73603</td></tr><tr><td>val/specificity_AC</td><td>0.98643</td></tr><tr><td>val/specificity_Ambiguous</td><td>0.97245</td></tr><tr><td>val/specificity_DL</td><td>0.9945</td></tr><tr><td>val/specificity_ECW</td><td>0.99729</td></tr><tr><td>val/specificity_ESW</td><td>0.99033</td></tr><tr><td>val/specificity_SA</td><td>0.96206</td></tr><tr><td>val/specificity_SW</td><td>0.98623</td></tr><tr><td>val/specificity_TA</td><td>0.97794</td></tr><tr><td>val/specificity_TAUL_TARL</td><td>0.96884</td></tr><tr><td>val/specificity_TCW</td><td>0.99323</td></tr><tr><td>val/specificity_UL_RL</td><td>0.98057</td></tr><tr><td>val/specificity_UPE_RPE</td><td>0.98462</td></tr><tr><td>val/specificity_macro</td><td>0.98287</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">repvgg_model-run</strong> at: <a href='https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d' target=\"_blank\">https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount/runs/10d6g77d</a><br> View project at: <a href='https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount' target=\"_blank\">https://wandb.ai/elharkaouimeriem-ensa/Fingerprint-classification-ridgecount</a><br>Synced 5 W&B file(s), 6 media file(s), 18 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250622_153157-10d6g77d/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if wandb.run is not None:\n",
        "    wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7306368,
          "sourceId": 11643609,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7366869,
          "sourceId": 11739334,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7630856,
          "sourceId": 12122732,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31011,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}